from baidupcs_py.baidupcs import BaiduPCSApi
from baidupcs_py.baidupcs.errors import BaiduPCSError
from loguru import logger
import json
import os
import time
import re
from notify import send as notify_send
import posixpath
from threading import Lock
import traceback
import subprocess
import shutil
import json
import random
from functools import wraps

def api_retry(max_retries=1, delay_range=(2, 3), exclude_errors=None):
    """
    APIé‡è¯•è£…é¥°å™¨
    Args:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤1æ¬¡ï¼Œå³æ€»å…±æ‰§è¡Œ2æ¬¡ï¼‰
        delay_range: é‡è¯•å»¶è¿ŸèŒƒå›´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤2-3ç§’
        exclude_errors: ä¸éœ€è¦é‡è¯•çš„é”™è¯¯ç åˆ—è¡¨
    """
    if exclude_errors is None:
        exclude_errors = [-6, 115, 145, 200025, -9]  # èº«ä»½éªŒè¯å¤±è´¥ã€åˆ†äº«é“¾æ¥å¤±æ•ˆã€æå–ç é”™è¯¯ã€æ–‡ä»¶ä¸å­˜åœ¨

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None

            for attempt in range(max_retries + 1):  # +1 å› ä¸ºåŒ…å«åŸå§‹è¯·æ±‚
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    error_str = str(e)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸éœ€è¦é‡è¯•çš„é”™è¯¯
                    should_skip_retry = False
                    for error_code in exclude_errors:
                        if f"error_code: {error_code}" in error_str or f"errno: {error_code}" in error_str:
                            should_skip_retry = True
                            break

                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•æˆ–è€…æ˜¯ä¸éœ€è¦é‡è¯•çš„é”™è¯¯ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
                    if attempt == max_retries or should_skip_retry:
                        if should_skip_retry:
                            logger.debug(f"APIè°ƒç”¨å¤±è´¥ï¼Œé”™è¯¯ä¸éœ€è¦é‡è¯•: {error_str}")
                        raise e

                    # è®°å½•é‡è¯•ä¿¡æ¯
                    delay = random.uniform(delay_range[0], delay_range[1])
                    logger.warning(f"APIè°ƒç”¨å¤±è´¥ï¼Œ{delay:.1f}ç§’åè¿›è¡Œç¬¬{attempt + 1}æ¬¡é‡è¯•: {error_str}")
                    time.sleep(delay)

            # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªå¼‚å¸¸
            raise last_exception

        return wrapper
    return decorator

class BaiduStorage:
    def __init__(self):
        self._client_lock = Lock()  # æ·»åŠ å®¢æˆ·ç«¯åˆå§‹åŒ–é”
        self.config = self._load_config()
        self.client = None
        self._init_client()
        self.last_request_time = 0
        self.min_request_interval = 2
        # æ·»åŠ é”™è¯¯è·Ÿè¸ª
        self.last_error = None
        self.task_locks = {}  # ç”¨äºå­˜å‚¨æ¯ä¸ªä»»åŠ¡çš„é”
        # æ·»åŠ ç”¨æˆ·ä¿¡æ¯ç¼“å­˜
        self._user_info_cache = None
        self._user_info_cache_time = 0
        self._cache_ttl = 30  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        
    def _load_config(self):
        try:
            # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
            if not os.path.exists('config/config.json') or os.path.getsize('config/config.json') == 0:
                logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œå°†ä»æ¨¡æ¿åˆ›å»º")
                self._create_config_from_template()
            
            with open('config/config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                # ç¡®ä¿é…ç½®æ–‡ä»¶ç»“æ„å®Œæ•´
                if 'baidu' not in config:
                    config['baidu'] = {}
                if 'users' not in config['baidu']:
                    config['baidu']['users'] = {}
                if 'current_user' not in config['baidu']:
                    config['baidu']['current_user'] = None
                if 'tasks' not in config['baidu']:
                    config['baidu']['tasks'] = []
                if 'cron' not in config:
                    config['cron'] = {
                        'default_schedule': '*/5 * * * *',
                        'auto_install': True
                    }
                # æ·»åŠ  auth é…ç½®ç»“æ„
                if 'auth' not in config:
                    config['auth'] = {
                        'users': 'admin',
                        'password': 'admin123',
                        'session_timeout': 3600
                    }
                return config
        except FileNotFoundError:
            return {
                'baidu': {
                    'users': {},
                    'current_user': None,
                    'tasks': []
                },
                'cron': {
                    'default_schedule': '*/5 * * * *',
                    'auto_install': True
                },
                'auth': {
                    'users': 'admin',
                    'password': 'admin123',
                    'session_timeout': 3600
                }
            }
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise
    
    def _create_config_from_template(self):
        """ä»æ¨¡æ¿åˆ›å»ºé…ç½®æ–‡ä»¶"""
        try:
            # æŸ¥æ‰¾æ¨¡æ¿æ–‡ä»¶
            template_paths = [
                'config/config.template.json',
                'template/config.template.json'
            ]
            
            template_path = None
            for path in template_paths:
                if os.path.exists(path):
                    template_path = path
                    break
            
            if not template_path:
                logger.error("æ‰¾ä¸åˆ°é…ç½®æ¨¡æ¿æ–‡ä»¶")
                raise FileNotFoundError("é…ç½®æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨")
            
            # å¤‡ä»½ç°æœ‰é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if os.path.exists('config/config.json'):
                backup_path = f'config/config.json.backup.{int(time.time())}'
                shutil.copy2('config/config.json', backup_path)
                logger.info(f"å·²å¤‡ä»½ç°æœ‰é…ç½®æ–‡ä»¶åˆ°: {backup_path}")
            
            # ä»æ¨¡æ¿å¤åˆ¶é…ç½®æ–‡ä»¶
            os.makedirs('config', exist_ok=True)
            shutil.copy2(template_path, 'config/config.json')
            logger.info(f"å·²ä»æ¨¡æ¿ {template_path} åˆ›å»ºé…ç½®æ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"ä»æ¨¡æ¿åˆ›å»ºé…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise
            
    def _save_config(self, update_scheduler=True):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            # åœ¨ä¿å­˜å‰æ¸…ç† None å€¼çš„ cron å­—æ®µ
            for task in self.config.get('baidu', {}).get('tasks', []):
                if 'cron' in task and task['cron'] is None:
                    del task['cron']
                    
            with open('config/config.json', 'w', encoding='utf-8') as f:
                json.dump(self.config, f, ensure_ascii=False, indent=4)
            
            logger.debug("é…ç½®ä¿å­˜æˆåŠŸ")
            
            # ç¡®ä¿é…ç½®å·²ç»å†™å…¥æ–‡ä»¶
            with open('config/config.json', 'r', encoding='utf-8') as f:
                saved_config = json.load(f)
                if saved_config != self.config:
                    logger.error("é…ç½®ä¿å­˜éªŒè¯å¤±è´¥")
                    raise Exception("é…ç½®ä¿å­˜éªŒè¯å¤±è´¥")
            
            # é€šçŸ¥è°ƒåº¦å™¨æ›´æ–°ä»»åŠ¡
            if update_scheduler:
                from scheduler import TaskScheduler
                if hasattr(TaskScheduler, 'instance') and TaskScheduler.instance:
                    TaskScheduler.instance.update_tasks()
            
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
            raise
            
    def _init_client(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        with self._client_lock:  # ä½¿ç”¨é”ä¿æŠ¤åˆå§‹åŒ–è¿‡ç¨‹
            try:
                current_user = self.config['baidu'].get('current_user')
                if not current_user:
                    logger.error("æœªè®¾ç½®å½“å‰ç”¨æˆ·")
                    return False
                    
                user_info = self.config['baidu']['users'].get(current_user)
                if not user_info or not user_info.get('cookies'):
                    logger.error(f"ç”¨æˆ· {current_user} é…ç½®æ— æ•ˆ")
                    return False
                    
                cookies = self._parse_cookies(user_info['cookies'])
                if not self._validate_cookies(cookies):
                    logger.error("cookies æ— æ•ˆ")
                    return False
                    
                # æ¸…é™¤ç”¨æˆ·ä¿¡æ¯ç¼“å­˜
                self._clear_user_info_cache()
                
                # ä½¿ç”¨é‡è¯•æœºåˆ¶åˆå§‹åŒ–å®¢æˆ·ç«¯
                for retry in range(3):
                    try:
                        self.client = BaiduPCSApi(cookies=cookies)
                        # éªŒè¯å®¢æˆ·ç«¯
                        quota = self.client.quota()
                        total_gb = round(quota[0] / (1024**3), 2)
                        used_gb = round(quota[1] / (1024**3), 2)
                        logger.info(f"å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œç½‘ç›˜æ€»ç©ºé—´: {total_gb}GB, å·²ä½¿ç”¨: {used_gb}GB")
                        return True
                    except Exception as e:
                        if retry < 2:
                            logger.warning(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œç­‰å¾…é‡è¯•: {str(e)}")
                            time.sleep(3)
                        else:
                            logger.error(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                            return False
                            
            except Exception as e:
                logger.error(f"åˆå§‹åŒ–å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
                return False
            
    def _validate_cookies(self, cookies):
        """éªŒè¯cookiesæ˜¯å¦æœ‰æ•ˆ
        Args:
            cookies: cookieså­—å…¸
        Returns:
            bool: æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            required_cookies = ['BDUSS', 'STOKEN']
            missing = [c for c in required_cookies if c not in cookies]
            if missing:
                logger.error(f'ç¼ºå°‘å¿…è¦çš„ cookies: {missing}')
                return False
            return True
        except Exception as e:
            logger.error(f"éªŒè¯cookieså¤±è´¥: {str(e)}")
            return False
            
    def _parse_cookies(self, cookies_str):
        """è§£æ cookies å­—ç¬¦ä¸²ä¸ºå­—å…¸
        Args:
            cookies_str: cookies å­—ç¬¦ä¸²ï¼Œæ ¼å¼å¦‚ 'key1=value1; key2=value2'
        Returns:
            dict: cookies å­—å…¸
        """
        cookies = {}
        if not cookies_str:
            return cookies
            
        items = cookies_str.split(';')
        for item in items:
            if not item.strip():
                continue
            if '=' not in item:
                continue
            key, value = item.split('=', 1)
            cookies[key.strip()] = value.strip()
        return cookies
        
    def add_user_from_cookies(self, cookies_str, username=None):
        """ç›´æ¥ä» cookies å­—ç¬¦ä¸²æ·»åŠ ç”¨æˆ·
        Args:
            cookies_str: cookies å­—ç¬¦ä¸²
            username: æŒ‡å®šç”¨æˆ·å,å¯é€‰
        """
        try:
            # è§£æ cookies å­—ç¬¦ä¸²ä¸ºå­—å…¸
            cookies_dict = self._parse_cookies(cookies_str)
            if not cookies_dict:
                raise ValueError("æ— æ•ˆçš„ cookies æ ¼å¼")
                
            # éªŒè¯ cookies æ˜¯å¦æœ‰æ•ˆ
            temp_api = BaiduPCSApi(cookies=cookies_dict)
            user_info = temp_api.user_info()
            
            if not user_info:
                raise ValueError("Cookies æ— æ•ˆ")
                
            # ä½¿ç”¨æŒ‡å®šç”¨æˆ·åæˆ–ç”Ÿæˆå”¯ä¸€ç”¨æˆ·å
            if not username:
                username = "user"
            if username in self.config['baidu']['users']:
                i = 1
                while f"{username}_{i}" in self.config['baidu']['users']:
                    i += 1
                username = f"{username}_{i}"
                
            # ä¿å­˜ç”¨æˆ·ä¿¡æ¯
            self.config['baidu']['users'][username] = {
                "cookies": cookies_str,
                "name": username,
                "user_id": username
            }
            
            # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªç”¨æˆ·,è®¾ä¸ºå½“å‰ç”¨æˆ·
            if not self.config['baidu']['current_user']:
                self.config['baidu']['current_user'] = username
                
            self._save_config()
            
            # å¦‚æœæ·»åŠ çš„æ˜¯å½“å‰ç”¨æˆ·,é‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
            if username == self.config['baidu']['current_user']:
                self._init_client()
                
            logger.success(f"æˆåŠŸæ·»åŠ ç”¨æˆ·: {username}")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ ç”¨æˆ·å¤±è´¥: {str(e)}")
            return False
    
    def add_user(self, cookies=None, bduss=None, stoken=None, username=None):
        """æ·»åŠ ç™¾åº¦ç½‘ç›˜ç”¨æˆ·
        Args:
            cookies: å®Œæ•´çš„ cookies å­—ç¬¦ä¸²
            bduss: BDUSS å€¼
            stoken: STOKEN å€¼,ç”¨äºåˆ†äº«åŠŸèƒ½
            username: ç”¨æˆ·å,ä¸æŒ‡å®šåˆ™ä½¿ç”¨ç™¾åº¦è¿”å›çš„ç”¨æˆ·å
        """
        try:
            if not (cookies or bduss):
                raise ValueError("cookies å’Œ bduss è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ª")
                
            if cookies:
                return self.add_user_from_cookies(cookies, username)
                
            # æ„é€  cookies å­—ç¬¦ä¸²
            cookies = f"BDUSS={bduss}"
            if stoken:
                cookies += f"; STOKEN={stoken}"
                
            return self.add_user_from_cookies(cookies, username)
            
        except Exception as e:
            logger.error(f"æ·»åŠ ç”¨æˆ·å¤±è´¥: {str(e)}")
            return False
            
    def _clear_user_info_cache(self):
        """æ¸…é™¤ç”¨æˆ·ä¿¡æ¯ç¼“å­˜"""
        self._user_info_cache = None
        self._user_info_cache_time = 0
        logger.debug("å·²æ¸…é™¤ç”¨æˆ·ä¿¡æ¯ç¼“å­˜")
        
    def switch_user(self, username):
        """åˆ‡æ¢å½“å‰ç”¨æˆ·"""
        try:
            if username not in self.config['baidu']['users']:
                raise ValueError(f"ç”¨æˆ· {username} ä¸å­˜åœ¨")
                
            self.config['baidu']['current_user'] = username
            self._save_config()
            self._init_client()
            # æ¸…é™¤ç”¨æˆ·ä¿¡æ¯ç¼“å­˜
            self._clear_user_info_cache()
            
            logger.success(f"å·²åˆ‡æ¢åˆ°ç”¨æˆ·: {username}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ‡æ¢ç”¨æˆ·å¤±è´¥: {str(e)}")
            return False
            
    def remove_user(self, username):
        """åˆ é™¤ç”¨æˆ·"""
        try:
            if username not in self.config['baidu']['users']:
                raise ValueError(f"ç”¨æˆ· {username} ä¸å­˜åœ¨")
                
            # ä¸èƒ½åˆ é™¤å½“å‰ç”¨æˆ·
            if username == self.config['baidu']['current_user']:
                raise ValueError("ä¸èƒ½åˆ é™¤å½“å‰ä½¿ç”¨çš„ç”¨æˆ·")
                
            del self.config['baidu']['users'][username]
            self._save_config()
            
            logger.success(f"å·²åˆ é™¤ç”¨æˆ·: {username}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤ç”¨æˆ·å¤±è´¥: {str(e)}")
            return False
            
    def list_users(self):
        """è·å–ç”¨æˆ·åˆ—è¡¨"""
        users = []
        current_user = self.config['baidu'].get('current_user')
        
        for username, user_info in self.config['baidu'].get('users', {}).items():
            users.append({
                'username': username,
                'name': user_info.get('name', username),
                'user_id': user_info.get('user_id', username)
            })
        
        return users
            
    def get_user_info(self):
        """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
        try:
            if not self.client:
                return None
            
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
            current_time = time.time()
            if (self._user_info_cache is not None and 
                current_time - self._user_info_cache_time < self._cache_ttl):
                logger.debug("ä½¿ç”¨ç¼“å­˜çš„ç”¨æˆ·ä¿¡æ¯ï¼Œè·³è¿‡APIè°ƒç”¨")
                return self._user_info_cache
            
            # é¦–å…ˆå°è¯•è·å–é…é¢ä¿¡æ¯
            try:
                quota_info = self.client.quota()
                if isinstance(quota_info, (tuple, list)):
                    quota = {
                        'total': quota_info[0],
                        'used': quota_info[1]
                    }
                else:
                    quota = quota_info
                logger.debug("æˆåŠŸè·å–ç½‘ç›˜é…é¢ä¿¡æ¯")
                
                # åˆ†æ­¥è·å–ç”¨æˆ·ä¿¡æ¯
                try:
                    # 1. å…ˆè·å–ç½‘ç›˜ç”¨æˆ·ä¿¡æ¯
                    logger.debug("å¼€å§‹è·å–ç½‘ç›˜ç”¨æˆ·ä¿¡æ¯...")
                    pan_info = self.client._baidupcs.user_info()
                    logger.debug(f"ç½‘ç›˜ç”¨æˆ·ä¿¡æ¯: {pan_info}")
                    
                    user_id = int(pan_info["user"]["id"])
                    user_name = pan_info["user"]["name"]
                    
                    # æ„å»ºå¹¶ç¼“å­˜ç”¨æˆ·ä¿¡æ¯
                    user_info = {
                        'user_name': user_name,
                        'user_id': user_id,
                        'quota': quota
                    }
                    
                    # æ›´æ–°ç¼“å­˜
                    self._user_info_cache = user_info
                    self._user_info_cache_time = current_time
                    
                    return user_info
                    
                except Exception as e:
                    logger.warning(f"è·å–ç”¨æˆ·è¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")
                    
                    # å³ä½¿è·å–è¯¦ç»†ä¿¡æ¯å¤±è´¥ï¼Œä¹Ÿç¼“å­˜åŸºæœ¬é…é¢ä¿¡æ¯
                    user_info = {
                        'user_name': 'æœªçŸ¥ç”¨æˆ·',
                        'user_id': None,
                        'quota': quota
                    }
                    self._user_info_cache = user_info
                    self._user_info_cache_time = current_time
                    
                    return user_info
                    
            except Exception as e:
                logger.error(f"è·å–ç½‘ç›˜ä¿¡æ¯å¤±è´¥: {str(e)}")
                return None
                
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
            
    def _save_record(self, share_url, status):
        """ä¿å­˜è½¬å­˜è®°å½•
        Args:
            share_url: åˆ†äº«é“¾æ¥
            status: è½¬å­˜çŠ¶æ€,Trueè¡¨ç¤ºæˆåŠŸ,Falseè¡¨ç¤ºå¤±è´¥
        """
        try:
            record = {
                "url": share_url,
                "time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "status": "æˆåŠŸ" if status else "å¤±è´¥"
            }
            
            records = []
            try:
                with open('file_records.json', 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    if content:  # åªæœ‰å½“æ–‡ä»¶ä¸ä¸ºç©ºæ—¶æ‰è§£æ
                        records = json.loads(content)
                    if not isinstance(records, list):
                        records = []
            except FileNotFoundError:
                # æ–‡ä»¶ä¸å­˜åœ¨æ—¶åˆ›å»ºç©ºåˆ—è¡¨
                records = []
                
            records.append(record)
            
            with open('file_records.json', 'w', encoding='utf-8') as f:
                json.dump(records, f, ensure_ascii=False, indent=4)
                
        except Exception as e:
            logger.error(f"ä¿å­˜è½¬å­˜è®°å½•å¤±è´¥: {str(e)}")
            
    def get_max_order(self):
        """è·å–å½“å‰æœ€å¤§çš„ä»»åŠ¡é¡ºåºå€¼"""
        try:
            tasks = self.config['baidu'].get('tasks', [])
            if not tasks:
                return 0
            return max((task.get('order', 0) for task in tasks), default=0)
        except Exception as e:
            logger.error(f"è·å–æœ€å¤§é¡ºåºå€¼å¤±è´¥: {str(e)}")
            return 0

    def _update_task_orders(self):
        """é‡æ–°æ•´ç†æ‰€æœ‰ä»»åŠ¡çš„é¡ºåº"""
        try:
            tasks = self.config['baidu'].get('tasks', [])
            # æŒ‰ç°æœ‰orderæ’åºï¼Œæ²¡æœ‰orderçš„æ’åœ¨æœ€å
            tasks.sort(key=lambda x: x.get('order', float('inf')))
            # é‡æ–°åˆ†é…orderï¼Œä»1å¼€å§‹
            for i, task in enumerate(tasks, 1):
                task['order'] = i
            self.config['baidu']['tasks'] = tasks
            self._save_config()
            return True
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡é¡ºåºå¤±è´¥: {str(e)}")
            return False

    def reorder_task(self, task_order, new_order):
        """è°ƒæ•´ä»»åŠ¡é¡ºåº
        Args:
            task_order: ä»»åŠ¡çš„å½“å‰order
            new_order: æ–°çš„é¡ºåºå€¼
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            tasks = self.config['baidu'].get('tasks', [])
            
            # æŸ¥æ‰¾è¦ç§»åŠ¨çš„ä»»åŠ¡
            task = next((t for t in tasks if t.get('order') == task_order), None)
            if not task:
                logger.error(f"æœªæ‰¾åˆ°ä»»åŠ¡: order={task_order}")
                return False
            
            # å¦‚æœæ–°é¡ºåºæ— æ•ˆï¼Œè¿”å›å¤±è´¥
            max_order = len(tasks)
            if not (1 <= new_order <= max_order):
                logger.error(f"æ— æ•ˆçš„æ–°é¡ºåº: {new_order}, æœ€å¤§å€¼: {max_order}")
                return False
            
            # è°ƒæ•´å…¶ä»–ä»»åŠ¡çš„é¡ºåº
            if new_order < task_order:
                # å‘å‰ç§»åŠ¨ï¼šä¸­é—´çš„ä»»åŠ¡é¡ºåº+1
                for t in tasks:
                    if new_order <= t.get('order', 0) < task_order:
                        t['order'] = t.get('order', 0) + 1
            else:
                # å‘åç§»åŠ¨ï¼šä¸­é—´çš„ä»»åŠ¡é¡ºåº-1
                for t in tasks:
                    if task_order < t.get('order', 0) <= new_order:
                        t['order'] = t.get('order', 0) - 1
            
            # è®¾ç½®æ–°é¡ºåº
            task['order'] = new_order
            
            # é‡æ–°æ’åºä»»åŠ¡åˆ—è¡¨
            tasks.sort(key=lambda x: x.get('order', float('inf')))
            self.config['baidu']['tasks'] = tasks
            self._save_config()
            
            logger.success(f"ä»»åŠ¡é‡æ’åºæˆåŠŸ: {task_order} -> {new_order}")
            return True
            
        except Exception as e:
            logger.error(f"è°ƒæ•´ä»»åŠ¡é¡ºåºå¤±è´¥: {str(e)}")
            return False

    def add_task(self, url, save_dir, pwd=None, name=None, cron=None, category=None, regex_pattern=None, regex_replace=None):
        """æ·»åŠ ä»»åŠ¡"""
        try:
            if not url or not save_dir:
                raise ValueError("åˆ†äº«é“¾æ¥å’Œä¿å­˜ç›®å½•ä¸èƒ½ä¸ºç©º")
            
            # ç§»é™¤URLä¸­çš„hashéƒ¨åˆ†
            url = url.split('#')[0]
            
            # å¤„ç†ç¬¬äºŒç§æ ¼å¼: https://pan.baidu.com/share/init?surl=xxx&pwd=xxx
            # æ³¨æ„ï¼šè¿™é‡Œä¸å¤„ç†pwdå‚æ•°ï¼Œå› ä¸ºpwdç”±è°ƒç”¨æ–¹ä¼ å…¥
            if '/share/init?' in url and 'surl=' in url:
                import urllib.parse
                parsed = urllib.parse.urlparse(url)
                params = urllib.parse.parse_qs(parsed.query)
                
                # æå–surlå‚æ•°
                surl = params.get('surl', [''])[0]
                
                # è½¬æ¢ä¸ºç¬¬ä¸€ç§æ ¼å¼
                if surl:
                    url = f"https://pan.baidu.com/s/{surl}"
            
            # éªŒè¯URLæ ¼å¼ï¼ˆæ›´æ–°æ­£åˆ™è¡¨è¾¾å¼ä»¥é€‚åº”å¯èƒ½çš„æŸ¥è¯¢å‚æ•°ï¼‰
            if not re.match(r'^https?://pan\.baidu\.com/s/[a-zA-Z0-9_-]+(?:\?pwd=[a-zA-Z0-9]+)?$', url):
                raise ValueError("æ— æ•ˆçš„ç™¾åº¦ç½‘ç›˜åˆ†äº«é“¾æ¥æ ¼å¼")
            
            # è·å–æ–°ä»»åŠ¡çš„é¡ºåºå€¼
            new_order = self.get_max_order() + 1
            
            # åˆ›å»ºæ–°ä»»åŠ¡
            new_task = {
                'url': url,
                'save_dir': save_dir,
                'pwd': pwd,
                'name': name or url,
                'status': 'pending',
                'transferred_files': [],
                'order': new_order
            }
            
            # æ·»åŠ å¯é€‰å­—æ®µ
            if cron:
                new_task['cron'] = cron
            if category:
                new_task['category'] = category.strip()
            if regex_pattern:
                new_task['regex_pattern'] = regex_pattern.strip()
                new_task['regex_replace'] = regex_replace.strip() if regex_replace else ''
            
            # æ·»åŠ ä»»åŠ¡
            tasks = self.config['baidu'].get('tasks', [])
            tasks.append(new_task)
            self.config['baidu']['tasks'] = tasks
            
            # ä¿å­˜é…ç½®
            self._save_config()
            
            # é€šçŸ¥è°ƒåº¦å™¨æ›´æ–°ä»»åŠ¡
            from scheduler import TaskScheduler
            if hasattr(TaskScheduler, 'instance') and TaskScheduler.instance:
                TaskScheduler.instance.add_single_task(new_task)
            
            logger.success(f"æ·»åŠ ä»»åŠ¡æˆåŠŸ: {new_task}")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
            
    def remove_task(self, share_url):
        """åˆ é™¤è½¬å­˜ä»»åŠ¡
        Args:
            share_url: åˆ†äº«é“¾æ¥
        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            tasks = self.config['baidu']['tasks']
            for i, task in enumerate(tasks):
                if task['url'] == share_url:
                    tasks.pop(i)
                    # ç¡®ä¿æ›´æ–°è°ƒåº¦å™¨
                    self._save_config(update_scheduler=True)
                    logger.success(f"åˆ é™¤ä»»åŠ¡æˆåŠŸ: {share_url}")
                    return True
            logger.warning(f"æœªæ‰¾åˆ°ä»»åŠ¡: {share_url}")
            return False
        except Exception as e:
            logger.error(f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
            
    def list_tasks(self):
        """åˆ—å‡ºæ‰€æœ‰è½¬å­˜ä»»åŠ¡"""
        return self.config['baidu']['tasks']
            
    def _normalize_path(self, path, file_only=False):
        """æ ‡å‡†åŒ–è·¯å¾„
        Args:
            path: åŸå§‹è·¯å¾„
            file_only: æ˜¯å¦åªè¿”å›æ–‡ä»¶å
        Returns:
            str: æ ‡å‡†åŒ–åçš„è·¯å¾„
        """
        try:
            # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ ï¼Œå»é™¤å¤šä½™æ–œæ 
            path = path.replace('\\', '/').strip('/')
            
            if file_only:
                # åªè¿”å›æ–‡ä»¶å
                return path.split('/')[-1]
            
            # ç¡®ä¿ç›®å½•ä»¥ / å¼€å¤´
            if not path.startswith('/'):
                path = '/' + path
            return path
        except Exception as e:
            logger.error(f"æ ‡å‡†åŒ–è·¯å¾„å¤±è´¥: {str(e)}")
            return path

    def _ensure_dir_exists(self, path, client=None):
        """ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        Args:
            path: ç›®å½•è·¯å¾„
            client: å®¢æˆ·ç«¯å®ä¾‹ï¼Œé»˜è®¤ä¸ºNoneåˆ™ä½¿ç”¨self.client
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if client is None:
                client = self.client

            path = self._normalize_path(path)

            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            try:
                client.list(path)
                logger.debug(f"ç›®å½•å·²å­˜åœ¨: {path}")
                return True
            except Exception as e:
                if 'error_code: 31066' in str(e):  # ç›®å½•ä¸å­˜åœ¨
                    logger.info(f"ç›®å½•ä¸å­˜åœ¨ï¼Œå¼€å§‹åˆ›å»º: {path}")
                    try:
                        client.makedir(path)
                        logger.success(f"åˆ›å»ºç›®å½•æˆåŠŸ: {path}")
                        return True
                    except Exception as create_e:
                        if 'error_code: 31062' in str(create_e):  # æ–‡ä»¶åéæ³•
                            logger.error(f"ç›®å½•åéæ³•: {path}")
                        elif 'file already exists' in str(create_e).lower():
                            # å¹¶å‘åˆ›å»ºæ—¶å¯èƒ½å‘ç”Ÿ
                            logger.debug(f"ç›®å½•å·²å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯å¹¶å‘åˆ›å»ºï¼‰: {path}")
                            return True
                        elif 'no such file or directory' in str(create_e).lower():
                            # éœ€è¦åˆ›å»ºçˆ¶ç›®å½•
                            parent_dir = os.path.dirname(path)
                            if parent_dir and parent_dir != '/':
                                logger.info(f"éœ€è¦å…ˆåˆ›å»ºçˆ¶ç›®å½•: {parent_dir}")
                                if self._ensure_dir_exists(parent_dir, client=client):
                                    # çˆ¶ç›®å½•åˆ›å»ºæˆåŠŸï¼Œé‡è¯•åˆ›å»ºå½“å‰ç›®å½•
                                    return self._ensure_dir_exists(path, client=client)
                                else:
                                    logger.error(f"åˆ›å»ºçˆ¶ç›®å½•å¤±è´¥: {parent_dir}")
                                    return False
                            logger.error(f"æ— æ³•åˆ›å»ºç›®å½•ï¼Œçˆ¶ç›®å½•ä¸å­˜åœ¨: {path}")
                            return False
                        else:
                            logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥: {path}, é”™è¯¯: {str(create_e)}")
                            return False
                else:
                    logger.error(f"æ£€æŸ¥ç›®å½•å¤±è´¥: {path}, é”™è¯¯: {str(e)}")
                    return False

        except Exception as e:
            logger.error(f"ç¡®ä¿ç›®å½•å­˜åœ¨æ—¶å‘ç”Ÿé”™è¯¯: {path}, é”™è¯¯: {str(e)}")
            return False

    def _ensure_dir_tree_exists(self, path, client=None):
        """ç¡®ä¿ç›®å½•æ ‘å­˜åœ¨ï¼Œä¼šæ£€æŸ¥å¹¶åˆ›å»ºæ‰€æœ‰å¿…è¦çš„çˆ¶ç›®å½•
        Args:
            path: ç›®å½•è·¯å¾„
            client: å®¢æˆ·ç«¯å®ä¾‹ï¼Œé»˜è®¤ä¸ºNoneåˆ™ä½¿ç”¨self.client
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if client is None:
                client = self.client

            path = self._normalize_path(path)

            # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›æˆåŠŸ
            try:
                client.list(path)
                logger.debug(f"ç›®å½•å·²å­˜åœ¨: {path}")
                return True
            except:
                pass

            # åˆ†è§£è·¯å¾„
            parts = path.strip('/').split('/')
            current_path = ''

            # é€çº§æ£€æŸ¥å’Œåˆ›å»ºç›®å½•
            for part in parts:
                if not part:
                    continue
                current_path = self._normalize_path(current_path + '/' + part)
                if not self._ensure_dir_exists(current_path, client=client):
                    return False

            return True

        except Exception as e:
            logger.error(f"åˆ›å»ºç›®å½•æ ‘å¤±è´¥: {str(e)}")
            return False

    def _handle_api_error(self, error):
        """å¤„ç†APIé”™è¯¯"""
        error_str = str(error)
        
        # å¸¸è§é”™è¯¯ç å¤„ç†
        error_map = {
            '-6': 'èº«ä»½éªŒè¯å¤±è´¥ï¼Œè¯·é‡æ–°ç™»å½•',
            '-9': 'æ–‡ä»¶ä¸å­˜åœ¨',
            '-62': 'å‚æ•°é”™è¯¯',
            '-65': 'è®¿é—®é¢‘ç‡é™åˆ¶',
            '-130': 'è¯·æ±‚é”™è¯¯',
        }
        
        for code, msg in error_map.items():
            if f'error_code: {code}' in error_str:
                return code, msg
                
        return None, error_str
    
    def _parse_share_error(self, error_str):
        """è§£æåˆ†äº«é“¾æ¥ç›¸å…³çš„é”™è¯¯ä¿¡æ¯ï¼Œè¿”å›ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
        Args:
            error_str: åŸå§‹é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
        Returns:
            str: ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        """
        try:
            # æ£€æŸ¥é”™è¯¯ç 115ï¼ˆåˆ†äº«æ–‡ä»¶ç¦æ­¢åˆ†äº«ï¼‰
            if 'error_code: 115' in error_str:
                return 'åˆ†äº«é“¾æ¥å·²å¤±æ•ˆï¼ˆæ–‡ä»¶ç¦æ­¢åˆ†äº«ï¼‰'
            
            # æ£€æŸ¥é”™è¯¯ç 145æˆ–errno: 145ï¼ˆåˆ†äº«é“¾æ¥å¤±æ•ˆï¼‰
            if 'error_code: 145' in error_str or "'errno': 145" in error_str:
                return 'åˆ†äº«é“¾æ¥å·²å¤±æ•ˆ'
            
            # æ£€æŸ¥é”™è¯¯ç 200025ï¼ˆæå–ç é”™è¯¯ï¼‰
            if 'error_code: 200025' in error_str or "'errno': 200025" in error_str:
                return 'æå–ç è¾“å…¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥æå–ç '
            
            # æ£€æŸ¥å…¶ä»–å¸¸è§åˆ†äº«é”™è¯¯
            if 'share' in error_str.lower() and 'not found' in error_str.lower():
                return 'åˆ†äº«é“¾æ¥ä¸å­˜åœ¨æˆ–å·²å¤±æ•ˆ'
                
            if 'password' in error_str.lower() and 'wrong' in error_str.lower():
                return 'æå–ç é”™è¯¯'
                
            # å¦‚æœåŒ…å«å¤æ‚çš„JSONé”™è¯¯ä¿¡æ¯ï¼Œå°è¯•ç®€åŒ–
            if '{' in error_str and 'errno' in error_str:
                # å°è¯•æå–é”™è¯¯ç 
                import re
                errno_match = re.search(r"'errno':\s*(\d+)", error_str)
                if errno_match:
                    errno = int(errno_match.group(1))
                    if errno == 145:
                        return 'åˆ†äº«é“¾æ¥å·²å¤±æ•ˆ'
                    elif errno == 200025:
                        return 'æå–ç è¾“å…¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥æå–ç '
                    elif errno == 115:
                        return 'åˆ†äº«é“¾æ¥å·²å¤±æ•ˆï¼ˆæ–‡ä»¶ç¦æ­¢åˆ†äº«ï¼‰'
                    else:
                        return f'åˆ†äº«é“¾æ¥è®¿é—®å¤±è´¥ï¼ˆé”™è¯¯ç ï¼š{errno}ï¼‰'
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šé”™è¯¯ï¼Œè¿”å›ç®€åŒ–åçš„åŸå§‹é”™è¯¯
            # ç§»é™¤å¤æ‚çš„JSONä¿¡æ¯
            if len(error_str) > 200 and '{' in error_str:
                return 'åˆ†äº«é“¾æ¥è®¿é—®å¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥å’Œæå–ç '
            
            return error_str
            
        except Exception as e:
            logger.debug(f"è§£æåˆ†äº«é”™è¯¯ä¿¡æ¯å¤±è´¥: {str(e)}")
            return 'åˆ†äº«é“¾æ¥è®¿é—®å¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥å’Œæå–ç '

    def _handle_folder_structure(self, shared_paths, save_dir):
        """å¤„ç†æ–‡ä»¶å¤¹ç»“æ„
        Args:
            shared_paths: åˆ†äº«çš„è·¯å¾„åˆ—è¡¨
            save_dir: ä¿å­˜ç›®å½•
        Returns:
            tuple: (ç›®æ ‡ç›®å½•, æ˜¯å¦ä¸ºå•æ–‡ä»¶å¤¹)
        """
        try:
            if not shared_paths:
                return save_dir, False
                
            # æ£€æŸ¥æ˜¯å¦åªæœ‰ä¸€ä¸ªæ–‡ä»¶å¤¹
            if len(shared_paths) == 1 and shared_paths[0].is_dir:
                # å•æ–‡ä»¶å¤¹æƒ…å†µï¼šç›´æ¥ä½¿ç”¨ä¿å­˜ç›®å½•
                logger.info("æ£€æµ‹åˆ°å•ä¸ªæ–‡ä»¶å¤¹åˆ†äº«ï¼Œå†…å®¹å°†ç›´æ¥ä¿å­˜åˆ°ç›®æ ‡ç›®å½•")
                return save_dir, True
                
            # å¤šæ–‡ä»¶/æ–‡ä»¶å¤¹æƒ…å†µï¼šä¿æŒåŸæœ‰ç»“æ„
            logger.info("æ£€æµ‹åˆ°å¤šä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹ï¼Œå°†ä¿æŒåŸæœ‰ç›®å½•ç»“æ„")
            return save_dir, False
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤¹ç»“æ„æ—¶å‡ºé”™: {str(e)}")
            return save_dir, False

    def _apply_regex_rules(self, file_path, task_config):
        """åº”ç”¨æ­£åˆ™å¤„ç†è§„åˆ™ (å•ä¸ªpattern+replace)
        Args:
            file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
            task_config: ä»»åŠ¡é…ç½®ï¼ˆåŒ…å«æ­£åˆ™è§„åˆ™ï¼‰
        Returns:
            tuple: (should_transfer, final_path)
                should_transfer: æ˜¯å¦åº”è¯¥è½¬å­˜ï¼ˆFalseè¡¨ç¤ºè¢«è¿‡æ»¤æ‰ï¼‰
                final_path: å¤„ç†åçš„æ–‡ä»¶è·¯å¾„
        """
        try:
            # è·å–æ­£åˆ™è§„åˆ™
            pattern = task_config.get('regex_pattern', '')
            replace = task_config.get('regex_replace', '')
            
            if not pattern:
                # æ²¡æœ‰è§„åˆ™ï¼Œç›´æ¥è¿”å›åŸæ–‡ä»¶
                return True, file_path
            
            try:
                # 1. å°è¯•åŒ¹é…
                match = re.search(pattern, file_path)
                if not match:
                    # åŒ¹é…å¤±è´¥ = æ–‡ä»¶è¢«è¿‡æ»¤æ‰
                    logger.debug(f"æ–‡ä»¶è¢«æ­£åˆ™è§„åˆ™è¿‡æ»¤: {file_path} (è§„åˆ™: {pattern})")
                    return False, file_path
                
                # 2. åŒ¹é…æˆåŠŸï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡å‘½å
                if replace and replace.strip():
                    # æœ‰æ›¿æ¢å†…å®¹ï¼Œæ‰§è¡Œé‡å‘½å
                    new_path = re.sub(pattern, replace, file_path)
                    if new_path != file_path:
                        logger.debug(f"æ­£åˆ™é‡å‘½å: {file_path} -> {new_path}")
                        return True, new_path
                
                # 3. åŒ¹é…æˆåŠŸä½†æ— é‡å‘½åï¼Œè¿”å›åŸè·¯å¾„
                return True, file_path
                
            except re.error as e:
                logger.warning(f"æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {pattern}, é”™è¯¯: {str(e)}")
                # æ­£åˆ™é”™è¯¯æ—¶ä¸è¿‡æ»¤ï¼Œè¿”å›åŸæ–‡ä»¶
                return True, file_path
            
        except Exception as e:
            logger.error(f"åº”ç”¨æ­£åˆ™è§„åˆ™æ—¶å‡ºé”™: {str(e)}")
            # å‡ºé”™æ—¶è¿”å›åŸå§‹è·¯å¾„ï¼Œä¸å½±å“æ­£å¸¸æµç¨‹
            return True, file_path

    def transfer_share(self, share_url, pwd=None, new_files=None, save_dir=None, progress_callback=None, task_config=None):
        """è½¬å­˜åˆ†äº«æ–‡ä»¶
        Args:
            share_url: åˆ†äº«é“¾æ¥
            pwd: æå–ç 
            new_files: æŒ‡å®šè¦è½¬å­˜çš„æ–‡ä»¶åˆ—è¡¨
            save_dir: ä¿å­˜ç›®å½•
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            task_config: ä»»åŠ¡é…ç½®ï¼ˆåŒ…å«æ­£åˆ™è§„åˆ™ç­‰ï¼‰
        Returns:
            dict: {
                'success': bool,  # æ˜¯å¦æˆåŠŸ
                'message': str,   # æˆåŠŸæ—¶çš„æ¶ˆæ¯
                'error': str,     # å¤±è´¥æ—¶çš„é”™è¯¯ä¿¡æ¯
                'skipped': bool,  # æ˜¯å¦è·³è¿‡ï¼ˆæ²¡æœ‰æ–°æ–‡ä»¶ï¼‰
                'transferred_files': list  # æˆåŠŸè½¬å­˜çš„æ–‡ä»¶åˆ—è¡¨
            }
        """
        try:
            # åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯ç”¨äºæœ¬æ¬¡ä»»åŠ¡æ‰§è¡Œ
            logger.info("åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯ç”¨äºä»»åŠ¡æ‰§è¡Œ")
            current_user = self.config['baidu'].get('current_user')
            if not current_user:
                return {'success': False, 'error': 'æœªè®¾ç½®å½“å‰ç”¨æˆ·'}

            user_info = self.config['baidu']['users'].get(current_user)
            if not user_info or not user_info.get('cookies'):
                return {'success': False, 'error': f'ç”¨æˆ· {current_user} é…ç½®æ— æ•ˆ'}

            cookies = self._parse_cookies(user_info['cookies'])
            if not self._validate_cookies(cookies):
                return {'success': False, 'error': 'cookies æ— æ•ˆ'}

            # åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯
            temp_client = BaiduPCSApi(cookies=cookies)
            logger.info("ä¸´æ—¶å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")

            # è§„èŒƒåŒ–ä¿å­˜è·¯å¾„
            if save_dir and not save_dir.startswith('/'):
                save_dir = '/' + save_dir
            
            # æ­¥éª¤1ï¼šè®¿é—®åˆ†äº«é“¾æ¥å¹¶è·å–æ–‡ä»¶åˆ—è¡¨
            logger.info(f"æ­£åœ¨è®¿é—®åˆ†äº«é“¾æ¥: {share_url}")
            if progress_callback:
                progress_callback('info', f'ã€æ­¥éª¤1/4ã€‘è®¿é—®åˆ†äº«é“¾æ¥: {share_url}')
            
            try:
                # è®¿é—®åˆ†äº«é“¾æ¥
                if pwd:
                    logger.info(f"ä½¿ç”¨å¯†ç  {pwd} è®¿é—®åˆ†äº«é“¾æ¥")
                if progress_callback:
                        progress_callback('info', f'ä½¿ç”¨å¯†ç è®¿é—®åˆ†äº«é“¾æ¥')
                self._access_shared_with_retry(share_url, pwd, client=temp_client)

                # æ­¥éª¤1.1ï¼šè·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨å¹¶è®°å½•
                logger.info("è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨...")
                shared_paths = self._shared_paths_with_retry(shared_url=share_url, client=temp_client)
                if not shared_paths:
                    logger.error("è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨å¤±è´¥")
                    if progress_callback:
                        progress_callback('error', 'è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨å¤±è´¥')
                    return {'success': False, 'error': 'è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨å¤±è´¥'}
                
                # è®°å½•åˆ†äº«æ–‡ä»¶ä¿¡æ¯
                logger.info(f"æˆåŠŸè·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨ï¼Œå…± {len(shared_paths)} é¡¹")
                
                # è·å–åˆ†äº«ä¿¡æ¯
                uk = shared_paths[0].uk
                share_id = shared_paths[0].share_id
                bdstoken = shared_paths[0].bdstoken
                
                # è®°å½•å…±äº«æ–‡ä»¶è¯¦æƒ…
                shared_files_info = []
                for path in shared_paths:
                    if path.is_dir:
                        logger.info(f"è®°å½•å…±äº«æ–‡ä»¶å¤¹: {path.path}")
                        # è·å–æ–‡ä»¶å¤¹å†…å®¹
                        folder_files = self._list_shared_dir_files(path, uk, share_id, bdstoken, client=temp_client)
                        for file_info in folder_files:
                            shared_files_info.append(file_info)
                            logger.debug(f"è®°å½•å…±äº«æ–‡ä»¶: {file_info['path']}")
                    else:
                        logger.debug(f"è®°å½•å…±äº«æ–‡ä»¶: {path.path}")
                        shared_files_info.append({
                            'server_filename': os.path.basename(path.path),
                            'fs_id': path.fs_id,
                            'path': path.path,
                            'size': path.size,
                            'isdir': 0
                        })
                
                logger.info(f"å…±è®°å½• {len(shared_files_info)} ä¸ªå…±äº«æ–‡ä»¶")
                if progress_callback:
                    progress_callback('info', f'è·å–åˆ° {len(shared_files_info)} ä¸ªå…±äº«æ–‡ä»¶')
                
                # æ­¥éª¤2ï¼šæ‰«ææœ¬åœ°ç›®å½•ä¸­çš„æ–‡ä»¶
                logger.info(f"ã€æ­¥éª¤2/4ã€‘æ‰«ææœ¬åœ°ç›®å½•: {save_dir}")
                if progress_callback:
                    progress_callback('info', f'ã€æ­¥éª¤2/4ã€‘æ‰«ææœ¬åœ°ç›®å½•: {save_dir}')
                
                # è·å–æœ¬åœ°æ–‡ä»¶åˆ—è¡¨
                local_files = []
                if save_dir:
                    local_files = self.list_local_files(save_dir, client=temp_client)
                    if progress_callback:
                        progress_callback('info', f'æœ¬åœ°ç›®å½•ä¸­æœ‰ {len(local_files)} ä¸ªæ–‡ä»¶')
                
                # æ­¥éª¤3ï¼šå‡†å¤‡è½¬å­˜ï¼ˆå¯¹æ¯”æ–‡ä»¶ã€å‡†å¤‡ç›®å½•ï¼‰
                target_dir = save_dir
                is_single_folder = (
                    len(shared_paths) == 1 
                    and shared_paths[0].is_dir 
                    and not new_files  # å¦‚æœæŒ‡å®šäº†å…·ä½“æ–‡ä»¶ï¼Œä¸è¦è·³è¿‡é¡¶å±‚ç›®å½•
                )
                
                logger.info(f"ã€æ­¥éª¤3/4ã€‘å‡†å¤‡è½¬å­˜: å¯¹æ¯”æ–‡ä»¶å’Œå‡†å¤‡ç›®å½•")
                if progress_callback:
                    progress_callback('info', f'ã€æ­¥éª¤3/4ã€‘å‡†å¤‡è½¬å­˜: å¯¹æ¯”æ–‡ä»¶å’Œå‡†å¤‡ç›®å½•')
                
                # æ­¥éª¤3.1ï¼šå¯¹æ¯”æ–‡ä»¶ï¼Œç¡®å®šéœ€è¦è½¬å­˜çš„æ–‡ä»¶
                logger.info("å¼€å§‹å¯¹æ¯”å…±äº«æ–‡ä»¶å’Œæœ¬åœ°æ–‡ä»¶...")
                transfer_list = []  # å­˜å‚¨(fs_id, dir_path, clean_path, final_path, need_rename)å…ƒç»„
                rename_only_list = []  # å­˜å‚¨ä»…éœ€é‡å‘½åçš„æ–‡ä»¶(None, dir_path, clean_path, final_path, True)
                
                # ä½¿ç”¨ä¹‹å‰æ”¶é›†çš„å…±äº«æ–‡ä»¶ä¿¡æ¯è¿›è¡Œå¯¹æ¯”
                for file_info in shared_files_info:
                    clean_path = file_info['path']
                    if is_single_folder and '/' in clean_path:
                        clean_path = '/'.join(clean_path.split('/')[1:])
                    
                    # ğŸ”„ æ–°é€»è¾‘ï¼šå…ˆåº”ç”¨æ­£åˆ™è§„åˆ™
                    should_transfer = True
                    final_path = clean_path
                    
                    if task_config:
                        should_transfer, final_path = self._apply_regex_rules(clean_path, task_config)
                        if not should_transfer:
                            logger.debug(f"æ–‡ä»¶è¢«æ­£åˆ™è¿‡æ»¤æ‰: {clean_path}")
                            if progress_callback:
                                progress_callback('info', f'æ–‡ä»¶è¢«æ­£åˆ™è¿‡æ»¤æ‰: {clean_path}')
                            continue
                    
                    # ğŸ”„ æ”¹è¿›çš„å»é‡æ£€æŸ¥é€»è¾‘
                    clean_normalized = self._normalize_path(clean_path, file_only=True)
                    final_normalized = self._normalize_path(final_path, file_only=True)
                    
                    # æ£€æŸ¥åŸæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    original_exists = clean_normalized in local_files
                    # æ£€æŸ¥é‡å‘½ååæ–‡ä»¶æ˜¯å¦å­˜åœ¨  
                    final_exists = final_normalized in local_files
                    
                    if final_path != clean_path:  # éœ€è¦é‡å‘½å
                        if original_exists and not final_exists:
                            # åŸæ–‡ä»¶å­˜åœ¨ä½†é‡å‘½ååçš„ä¸å­˜åœ¨ = ä»…éœ€é‡å‘½åï¼Œä¸éœ€è½¬å­˜
                            logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ä½†æœªé‡å‘½åï¼Œå°†æ‰§è¡Œé‡å‘½å: {clean_path} -> {final_path}")
                            if progress_callback:
                                progress_callback('info', f'æ–‡ä»¶éœ€é‡å‘½å: {clean_path} -> {final_path}')
                            # æ·»åŠ åˆ°é‡å‘½ååˆ—è¡¨ï¼ˆä¸è½¬å­˜ï¼‰
                            rename_only_list.append((None, target_dir, clean_path, final_path, True))
                            continue
                        elif final_exists:
                            # é‡å‘½ååçš„æ–‡ä»¶å·²å­˜åœ¨
                            logger.debug(f"é‡å‘½ååæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {final_path}")
                            if progress_callback:
                                progress_callback('info', f'æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {final_path}')
                            continue
                        # else: åŸæ–‡ä»¶å’Œé‡å‘½ååæ–‡ä»¶éƒ½ä¸å­˜åœ¨ï¼Œéœ€è¦è½¬å­˜+é‡å‘½å
                    else:  # ä¸éœ€è¦é‡å‘½å
                        if final_exists:
                            logger.debug(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {final_path}")
                            if progress_callback:
                                progress_callback('info', f'æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {final_path}')
                            continue
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨æŒ‡å®šçš„æ–‡ä»¶åˆ—è¡¨ä¸­ï¼ˆä½¿ç”¨åŸå§‹è·¯å¾„æ£€æŸ¥ï¼‰
                    if new_files is None or clean_path in new_files:
                        # ğŸ”„ è½¬å­˜æ—¶ç”¨åŸå§‹ç›®å½•è·¯å¾„ï¼Œé‡å‘½ååœ¨è½¬å­˜åå¤„ç†
                        if target_dir is not None and clean_path is not None:
                            # è½¬å­˜åˆ°åŸå§‹è·¯å¾„çš„ç›®å½•
                            target_path = posixpath.join(target_dir, clean_path)
                            dir_path = posixpath.dirname(target_path).replace('\\', '/')
                            need_rename = (final_path != clean_path)
                            transfer_list.append((file_info['fs_id'], dir_path, clean_path, final_path, need_rename))
                            
                            # æ—¥å¿—æ˜¾ç¤ºé‡å‘½åä¿¡æ¯
                            if need_rename:
                                logger.info(f"éœ€è¦è½¬å­˜æ–‡ä»¶: {clean_path} -> {final_path}")
                                if progress_callback:
                                    progress_callback('info', f'éœ€è¦è½¬å­˜æ–‡ä»¶: {clean_path} -> {final_path}')
                            else:
                                logger.info(f"éœ€è¦è½¬å­˜æ–‡ä»¶: {final_path}")
                                if progress_callback:
                                    progress_callback('info', f'éœ€è¦è½¬å­˜æ–‡ä»¶: {final_path}')
                
                # å¤„ç†ä»…éœ€é‡å‘½åçš„æ–‡ä»¶ï¼ˆæ— éœ€è½¬å­˜ï¼‰
                rename_only_success = []
                failed_rename_only = []  # æ”¶é›†å¤±è´¥çš„é‡å‘½åä»»åŠ¡
                if rename_only_list:
                    logger.info(f"=== å¤„ç†ä»…éœ€é‡å‘½åçš„æ–‡ä»¶ï¼ˆ{len(rename_only_list)}ä¸ªï¼‰===")
                    if progress_callback:
                        progress_callback('info', f'å¤„ç†ä»…éœ€é‡å‘½åçš„æ–‡ä»¶: {len(rename_only_list)}ä¸ª')
                    
                    for _, dir_path, clean_path, final_path, _ in rename_only_list:
                        retry_count = 0
                        max_retries = 1
                        delay_seconds = self.config.get('file_operations', {}).get('rename_delay_seconds', 0.5)
                        
                        while retry_count <= max_retries:
                            try:
                                original_full_path = posixpath.join(dir_path, os.path.basename(clean_path))
                                final_full_path = posixpath.join(dir_path, os.path.basename(final_path))
                                
                                if retry_count == 0:
                                    logger.info(f"é‡å‘½åå·²å­˜åœ¨çš„æ–‡ä»¶: {original_full_path} -> {final_full_path}")
                                    if progress_callback:
                                        progress_callback('info', f'é‡å‘½å: {os.path.basename(clean_path)} -> {os.path.basename(final_path)}')
                                else:
                                    logger.info(f"é‡è¯•é‡å‘½åæ–‡ä»¶: {original_full_path} -> {final_full_path} (ç¬¬{retry_count}æ¬¡é‡è¯•)")
                                    if progress_callback:
                                        progress_callback('info', f'é‡è¯•é‡å‘½å: {os.path.basename(clean_path)} -> {os.path.basename(final_path)}')
                                
                                temp_client.rename(original_full_path, final_full_path)
                                logger.success(f"é‡å‘½åæˆåŠŸ: {clean_path} -> {final_path}")
                                rename_only_success.append(final_path)
                                
                                # æ·»åŠ å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
                                if delay_seconds > 0:
                                    logger.debug(f"å»¶è¿Ÿ {delay_seconds} ç§’ä»¥é¿å…APIé¢‘ç‡é™åˆ¶")
                                    time.sleep(delay_seconds)
                                
                                break  # æˆåŠŸåè·³å‡ºé‡è¯•å¾ªç¯
                                
                            except Exception as e:
                                retry_count += 1
                                if retry_count <= max_retries:
                                    # é‡è¯•å‰å»¶é•¿å»¶è¿Ÿæ—¶é—´
                                    retry_delay = delay_seconds * 2
                                    logger.warning(f"é‡å‘½åå¤±è´¥ï¼Œå°†åœ¨ {retry_delay} ç§’åé‡è¯•: {str(e)}")
                                    if progress_callback:
                                        progress_callback('warning', f'é‡å‘½åå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•: {str(e)}')
                                    time.sleep(retry_delay)
                                else:
                                    # ç¬¬ä¸€è½®é‡è¯•éƒ½å¤±è´¥ï¼ŒåŠ å…¥æ‰¹é‡é‡è¯•åˆ—è¡¨
                                    logger.warning(f"é‡å‘½åå¤±è´¥ï¼Œå°†åœ¨æœ€åæ‰¹é‡é‡è¯•: {clean_path} -> {final_path}, é”™è¯¯: {str(e)}")
                                    failed_rename_only.append((dir_path, clean_path, final_path, str(e)))
                                    if progress_callback:
                                        progress_callback('warning', f'é‡å‘½åå¤±è´¥ï¼Œå°†ç¨åé‡è¯•: {str(e)}')
                
                # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦è½¬å­˜çš„æ–‡ä»¶
                if not transfer_list and not rename_only_success:
                    if progress_callback:
                        progress_callback('info', 'æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶')
                    return {'success': True, 'skipped': True, 'message': 'æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦è½¬å­˜'}
                
                if not transfer_list and rename_only_success:
                    # åªæœ‰é‡å‘½åæ“ä½œï¼Œæ²¡æœ‰è½¬å­˜
                    return {
                        'success': True,
                        'message': f'ä»…é‡å‘½åæ“ä½œå®Œæˆï¼Œå…±å¤„ç† {len(rename_only_success)} ä¸ªæ–‡ä»¶',
                        'transferred_files': rename_only_success
                    }
                
                if progress_callback:
                    progress_callback('info', f'æ‰¾åˆ° {len(transfer_list)} ä¸ªæ–°æ–‡ä»¶éœ€è¦è½¬å­˜')
                
                # æ­¥éª¤3.2ï¼šåˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•
                logger.info("ç¡®ä¿æ‰€æœ‰ç›®æ ‡ç›®å½•å­˜åœ¨")
                created_dirs = set()
                for _, dir_path, _, _, _ in transfer_list:
                    if dir_path not in created_dirs:
                        logger.info(f"æ£€æŸ¥ç›®å½•: {dir_path}")
                        if not self._ensure_dir_exists(dir_path, client=temp_client):
                            logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥: {dir_path}")
                            if progress_callback:
                                progress_callback('error', f'åˆ›å»ºç›®å½•å¤±è´¥: {dir_path}')
                            return {'success': False, 'error': f'åˆ›å»ºç›®å½•å¤±è´¥: {dir_path}'}
                        created_dirs.add(dir_path)
                
                # æ­¥éª¤4ï¼šæ‰§è¡Œæ–‡ä»¶è½¬å­˜
                logger.info(f"=== ã€æ­¥éª¤4/4ã€‘å¼€å§‹æ‰§è¡Œè½¬å­˜æ“ä½œ ===")
                logger.info(f"å…±éœ€è½¬å­˜ {len(transfer_list)} ä¸ªæ–‡ä»¶")
                if progress_callback:
                    progress_callback('info', f'ã€æ­¥éª¤4/4ã€‘å¼€å§‹æ‰§è¡Œè½¬å­˜æ“ä½œï¼Œå…± {len(transfer_list)} ä¸ªæ–‡ä»¶')
                
                # æŒ‰ç›®å½•åˆ†ç»„è¿›è¡Œè½¬å­˜
                success_count = 0
                grouped_transfers = {}
                for fs_id, dir_path, _, _, _ in transfer_list:
                    grouped_transfers.setdefault(dir_path, []).append(fs_id)
                
                total_files = len(transfer_list)
                current_file = 0
                
                # å¯¹æ¯ä¸ªç›®å½•è¿›è¡Œæ‰¹é‡è½¬å­˜
                logger.info(f"æŒ‰ç›®å½•åˆ†ç»„è¿›è¡Œè½¬å­˜ï¼Œå…± {len(grouped_transfers)} ä¸ªç›®å½•ç»„")
                for dir_path, fs_ids in grouped_transfers.items():
                    # ç¡®ä¿ç›®å½•è·¯å¾„ä½¿ç”¨æ­£æ–œæ 
                    dir_path = dir_path.replace('\\', '/')
                    if progress_callback:
                        progress_callback('info', f'è½¬å­˜åˆ°ç›®å½• {dir_path} ({len(fs_ids)} ä¸ªæ–‡ä»¶)')
                    
                    try:
                        logger.info(f"å¼€å§‹æ‰§è¡Œè½¬å­˜æ“ä½œ: æ­£åœ¨å°† {len(fs_ids)} ä¸ªæ–‡ä»¶è½¬å­˜åˆ° {dir_path}")
                        # ç¡®ä¿å®¢æˆ·ç«¯å’Œå‚æ•°éƒ½æœ‰æ•ˆ
                        if temp_client and uk is not None and share_id is not None and bdstoken is not None:
                            self._transfer_shared_paths_with_retry(
                                remotedir=dir_path,
                                fs_ids=fs_ids,
                                uk=int(uk),
                                share_id=int(share_id),
                                bdstoken=str(bdstoken),
                                shared_url=share_url,
                                client=temp_client
                            )
                        else:
                            error_msg = "è½¬å­˜å¤±è´¥: å®¢æˆ·ç«¯æˆ–å‚æ•°æ— æ•ˆ"
                            logger.error(error_msg)
                            raise ValueError(error_msg)
                        success_count += len(fs_ids)
                        current_file += len(fs_ids)
                        logger.success(f"è½¬å­˜æ“ä½œæˆåŠŸå®Œæˆ: {len(fs_ids)} ä¸ªæ–‡ä»¶å·²è½¬å­˜åˆ° {dir_path}")
                        if progress_callback:
                            progress_callback('success', f'æˆåŠŸè½¬å­˜åˆ° {dir_path}')
                    except Exception as e:
                        if "error_code: -65" in str(e):  # é¢‘ç‡é™åˆ¶
                            if progress_callback:
                                progress_callback('warning', 'è§¦å‘é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾…10ç§’åé‡è¯•...')
                            logger.warning(f"è½¬å­˜æ“ä½œå—åˆ°é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾…10ç§’åé‡è¯•: {dir_path}")
                            time.sleep(10)
                            try:
                                logger.info(f"é‡è¯•è½¬å­˜æ“ä½œ: æ­£åœ¨å°† {len(fs_ids)} ä¸ªæ–‡ä»¶è½¬å­˜åˆ° {dir_path}")
                                # ç¡®ä¿å®¢æˆ·ç«¯å’Œå‚æ•°éƒ½æœ‰æ•ˆ
                                if temp_client and uk is not None and share_id is not None and bdstoken is not None:
                                    self._transfer_shared_paths_with_retry(
                                        remotedir=dir_path,
                                        fs_ids=fs_ids,
                                        uk=int(uk),
                                        share_id=int(share_id),
                                        bdstoken=str(bdstoken),
                                        shared_url=share_url,
                                        client=temp_client
                                    )
                                else:
                                    error_msg = "é‡è¯•è½¬å­˜å¤±è´¥: å®¢æˆ·ç«¯æˆ–å‚æ•°æ— æ•ˆ"
                                    logger.error(error_msg)
                                    raise ValueError(error_msg)
                                success_count += len(fs_ids)
                                logger.success(f"é‡è¯•è½¬å­˜æˆåŠŸ: {len(fs_ids)} ä¸ªæ–‡ä»¶å·²è½¬å­˜åˆ° {dir_path}")
                                if progress_callback:
                                    progress_callback('success', f'é‡è¯•æˆåŠŸ: {dir_path}')
                            except Exception as retry_e:
                                logger.error(f"é‡è¯•è½¬å­˜å¤±è´¥: {dir_path} - {str(retry_e)}")
                                if progress_callback:
                                    progress_callback('error', f'è½¬å­˜å¤±è´¥: {dir_path} - {str(retry_e)}')
                                return {'success': False, 'error': f'è½¬å­˜å¤±è´¥: {dir_path} - {str(retry_e)}'}
                        else:
                            logger.error(f"è½¬å­˜æ“ä½œå¤±è´¥: {dir_path} - {str(e)}")
                            if progress_callback:
                                progress_callback('error', f'è½¬å­˜å¤±è´¥: {dir_path} - {str(e)}')
                            return {'success': False, 'error': f'è½¬å­˜å¤±è´¥: {dir_path} - {str(e)}'}
                    
                    time.sleep(1)  # é¿å…é¢‘ç‡é™åˆ¶
                
                # æ­¥éª¤5ï¼šæ‰§è¡Œé‡å‘½åæ“ä½œï¼ˆå¦‚æœéœ€è¦ï¼‰
                logger.info("=== ã€æ­¥éª¤5/5ã€‘æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å‘½åæ–‡ä»¶ ===")
                renamed_files = []
                rename_errors = []
                failed_transfer_rename = []  # æ”¶é›†è½¬å­˜åé‡å‘½åå¤±è´¥çš„æ–‡ä»¶
                
                for fs_id, dir_path, clean_path, final_path, need_rename in transfer_list:
                    if need_rename:
                        retry_count = 0
                        max_retries = 1
                        delay_seconds = self.config.get('file_operations', {}).get('rename_delay_seconds', 0.5)
                        
                        while retry_count <= max_retries:
                            try:
                                # æ„å»ºè½¬å­˜åçš„å®Œæ•´è·¯å¾„ï¼ˆåŸå§‹æ–‡ä»¶åï¼‰
                                original_full_path = posixpath.join(dir_path, os.path.basename(clean_path))
                                # æ„å»ºé‡å‘½ååçš„å®Œæ•´è·¯å¾„
                                final_full_path = posixpath.join(dir_path, os.path.basename(final_path))
                                
                                if retry_count == 0:
                                    logger.info(f"é‡å‘½åæ–‡ä»¶: {original_full_path} -> {final_full_path}")
                                    if progress_callback:
                                        progress_callback('info', f'é‡å‘½åæ–‡ä»¶: {os.path.basename(clean_path)} -> {os.path.basename(final_path)}')
                                else:
                                    logger.info(f"é‡è¯•é‡å‘½åæ–‡ä»¶: {original_full_path} -> {final_full_path} (ç¬¬{retry_count}æ¬¡é‡è¯•)")
                                    if progress_callback:
                                        progress_callback('info', f'é‡è¯•é‡å‘½åæ–‡ä»¶: {os.path.basename(clean_path)} -> {os.path.basename(final_path)}')
                                
                                # ä½¿ç”¨baidupcs-pyçš„renameæ–¹æ³•ï¼ˆéœ€è¦å®Œæ•´è·¯å¾„ï¼‰
                                temp_client.rename(original_full_path, final_full_path)

                                logger.success(f"é‡å‘½åæˆåŠŸ: {clean_path} -> {final_path}")
                                renamed_files.append(final_path)
                                
                                # æ·»åŠ å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
                                if delay_seconds > 0:
                                    logger.debug(f"å»¶è¿Ÿ {delay_seconds} ç§’ä»¥é¿å…APIé¢‘ç‡é™åˆ¶")
                                    time.sleep(delay_seconds)
                                
                                break  # æˆåŠŸåè·³å‡ºé‡è¯•å¾ªç¯
                                
                            except Exception as e:
                                retry_count += 1
                                if retry_count <= max_retries:
                                    # é‡è¯•å‰å»¶é•¿å»¶è¿Ÿæ—¶é—´
                                    retry_delay = delay_seconds * 2
                                    logger.warning(f"é‡å‘½åå¤±è´¥ï¼Œå°†åœ¨ {retry_delay} ç§’åé‡è¯•: {str(e)}")
                                    if progress_callback:
                                        progress_callback('warning', f'é‡å‘½åå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•: {str(e)}')
                                    time.sleep(retry_delay)
                                else:
                                    # ç¬¬ä¸€è½®é‡è¯•éƒ½å¤±è´¥ï¼ŒåŠ å…¥æ‰¹é‡é‡è¯•åˆ—è¡¨
                                    logger.warning(f"é‡å‘½åå¤±è´¥ï¼Œå°†åœ¨æœ€åæ‰¹é‡é‡è¯•: {clean_path} -> {final_path}, é”™è¯¯: {str(e)}")
                                    failed_transfer_rename.append((dir_path, clean_path, final_path, str(e)))
                                    if progress_callback:
                                        progress_callback('warning', f'é‡å‘½åå¤±è´¥ï¼Œå°†ç¨åé‡è¯•: {str(e)}')
                                    # é‡å‘½åå¤±è´¥æ—¶æš‚æ—¶ä½¿ç”¨åŸæ–‡ä»¶å
                                    renamed_files.append(clean_path)
                    else:
                        renamed_files.append(final_path)
                
                # è®°å½•è½¬å­˜çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆä½¿ç”¨æœ€ç»ˆæ–‡ä»¶åï¼‰+ ä»…é‡å‘½åçš„æ–‡ä»¶
                transferred_files = renamed_files + rename_only_success
                
                # æ‰¹é‡é‡è¯•å¤±è´¥çš„é‡å‘½åæ“ä½œ
                all_failed_files = failed_rename_only + failed_transfer_rename
                if all_failed_files:
                    logger.info(f"=== ã€æ‰¹é‡é‡è¯•ã€‘å¼€å§‹æ‰¹é‡é‡è¯• {len(all_failed_files)} ä¸ªé‡å‘½åå¤±è´¥çš„æ–‡ä»¶ ===")
                    if progress_callback:
                        progress_callback('info', f'å¼€å§‹æ‰¹é‡é‡è¯• {len(all_failed_files)} ä¸ªé‡å‘½åå¤±è´¥çš„æ–‡ä»¶')
                    
                    batch_retry_success = []
                    batch_retry_failed = []
                    delay_seconds = self.config.get('file_operations', {}).get('rename_delay_seconds', 0.5)
                    
                    for dir_path, clean_path, final_path, original_error in all_failed_files:
                        try:
                            original_full_path = posixpath.join(dir_path, os.path.basename(clean_path))
                            final_full_path = posixpath.join(dir_path, os.path.basename(final_path))
                            
                            logger.info(f"æ‰¹é‡é‡è¯•é‡å‘½å: {original_full_path} -> {final_full_path}")
                            if progress_callback:
                                progress_callback('info', f'æ‰¹é‡é‡è¯•: {os.path.basename(clean_path)} -> {os.path.basename(final_path)}')

                            temp_client.rename(original_full_path, final_full_path)

                            logger.success(f"æ‰¹é‡é‡è¯•æˆåŠŸ: {clean_path} -> {final_path}")
                            batch_retry_success.append((clean_path, final_path))
                            
                            # æ›´æ–°ç›¸åº”çš„æ–‡ä»¶åˆ—è¡¨
                            if clean_path in renamed_files:
                                # å¦‚æœåŸæ¥æ˜¯åŸæ–‡ä»¶åï¼Œç°åœ¨æ”¹ä¸ºæœ€ç»ˆæ–‡ä»¶å
                                idx = renamed_files.index(clean_path)
                                renamed_files[idx] = final_path
                            else:
                                # å¦‚æœæ˜¯rename_onlyçš„å¤±è´¥ï¼Œæ·»åŠ åˆ°æˆåŠŸåˆ—è¡¨
                                if (dir_path, clean_path, final_path, original_error) in failed_rename_only:
                                    rename_only_success.append(final_path)
                            
                            # æ·»åŠ å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
                            if delay_seconds > 0:
                                logger.debug(f"æ‰¹é‡é‡è¯•å»¶è¿Ÿ {delay_seconds} ç§’")
                                time.sleep(delay_seconds)
                                
                        except Exception as e:
                            logger.error(f"æ‰¹é‡é‡è¯•æœ€ç»ˆå¤±è´¥: {clean_path} -> {final_path}, é”™è¯¯: {str(e)}")
                            batch_retry_failed.append((clean_path, final_path, str(e)))
                            rename_errors.append(f"æ‰¹é‡é‡è¯•æœ€ç»ˆå¤±è´¥: {clean_path} -> {final_path}, é”™è¯¯: {str(e)}")
                            if progress_callback:
                                progress_callback('error', f'æ‰¹é‡é‡è¯•å¤±è´¥: {str(e)}')
                    
                    # æ‰¹é‡é‡è¯•ç»“æœæ±‡æ€»
                    if batch_retry_success:
                        logger.success(f"æ‰¹é‡é‡è¯•æˆåŠŸ {len(batch_retry_success)} ä¸ªæ–‡ä»¶")
                        if progress_callback:
                            progress_callback('success', f'æ‰¹é‡é‡è¯•æˆåŠŸ {len(batch_retry_success)} ä¸ªæ–‡ä»¶')
                    
                    if batch_retry_failed:
                        logger.error(f"æ‰¹é‡é‡è¯•ä»å¤±è´¥ {len(batch_retry_failed)} ä¸ªæ–‡ä»¶")
                        if progress_callback:
                            progress_callback('error', f'æ‰¹é‡é‡è¯•ä»å¤±è´¥ {len(batch_retry_failed)} ä¸ªæ–‡ä»¶')
                    
                    # æ›´æ–°transferred_files
                    transferred_files = renamed_files + rename_only_success
                
                # è®°å½•é‡å‘½åç»“æœ
                if rename_errors:
                    logger.warning(f"éƒ¨åˆ†æ–‡ä»¶é‡å‘½åå¤±è´¥ï¼Œå…± {len(rename_errors)} ä¸ªé”™è¯¯")
                elif any(need_rename for _, _, _, _, need_rename in transfer_list):
                    logger.success("æ‰€æœ‰éœ€è¦é‡å‘½åçš„æ–‡ä»¶éƒ½å·²æˆåŠŸé‡å‘½å")
                
                # è½¬å­˜ç»“æœæ±‡æ€»
                logger.info(f"=== è½¬å­˜æ“ä½œå®Œæˆï¼Œç»“æœæ±‡æ€» ===")
                logger.info(f"æ€»æ–‡ä»¶æ•°: {total_files}")
                logger.info(f"æˆåŠŸè½¬å­˜: {success_count}")
                
                # æ ¹æ®è½¬å­˜ç»“æœè¿”å›ä¸åŒçŠ¶æ€
                if success_count == total_files:  # å…¨éƒ¨æˆåŠŸ
                    logger.success(f"è½¬å­˜å…¨éƒ¨æˆåŠŸï¼Œå…± {success_count}/{total_files} ä¸ªæ–‡ä»¶")
                    if progress_callback:
                        progress_callback('success', f'è½¬å­˜å®Œæˆï¼ŒæˆåŠŸè½¬å­˜ {success_count}/{total_files} ä¸ªæ–‡ä»¶')
                    return {
                        'success': True,
                        'message': f'æˆåŠŸè½¬å­˜ {success_count}/{total_files} ä¸ªæ–‡ä»¶',
                        'transferred_files': transferred_files
                    }
                elif success_count > 0:  # éƒ¨åˆ†æˆåŠŸ
                    logger.warning(f"è½¬å­˜éƒ¨åˆ†æˆåŠŸï¼Œå…± {success_count}/{total_files} ä¸ªæ–‡ä»¶")
                    if progress_callback:
                        progress_callback('warning', f'éƒ¨åˆ†è½¬å­˜æˆåŠŸï¼ŒæˆåŠŸè½¬å­˜ {success_count}/{total_files} ä¸ªæ–‡ä»¶')
                    return {
                        'success': True,
                        'message': f'éƒ¨åˆ†è½¬å­˜æˆåŠŸï¼ŒæˆåŠŸè½¬å­˜ {success_count}/{total_files} ä¸ªæ–‡ä»¶',
                        'transferred_files': transferred_files[:success_count]
                    }
                else:  # å…¨éƒ¨å¤±è´¥
                    if progress_callback:
                        progress_callback('error', 'è½¬å­˜å¤±è´¥ï¼Œæ²¡æœ‰æ–‡ä»¶æˆåŠŸè½¬å­˜')
                    return {
                        'success': False,
                        'error': 'è½¬å­˜å¤±è´¥ï¼Œæ²¡æœ‰æ–‡ä»¶æˆåŠŸè½¬å­˜'
                    }
                
            except Exception as e:
                error_msg = str(e)
                # ä½¿ç”¨æ–°çš„é”™è¯¯è§£æå‡½æ•°
                parsed_error = self._parse_share_error(error_msg)
                if "error_code: 115" in error_msg:
                    return {'success': False, 'error': parsed_error}
                else:
                    return {'success': False, 'error': parsed_error}
            
        except Exception as e:
            logger.error(f"è½¬å­˜åˆ†äº«æ–‡ä»¶å¤±è´¥: {str(e)}")
            parsed_error = self._parse_share_error(str(e))
            return {'success': False, 'error': parsed_error}

    def get_share_folder_name(self, share_url, pwd=None):
        """è·å–åˆ†äº«é“¾æ¥çš„ä¸»æ–‡ä»¶å¤¹åç§°"""
        try:
            logger.info(f"æ­£åœ¨è·å–åˆ†äº«é“¾æ¥ä¿¡æ¯: {share_url}")
            
            # è®¿é—®åˆ†äº«é“¾æ¥
            if pwd:
                logger.info(f"ä½¿ç”¨å¯†ç è®¿é—®åˆ†äº«é“¾æ¥")
            self._access_shared_with_retry(share_url, pwd)

            # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
            shared_paths = self._shared_paths_with_retry(shared_url=share_url)
            if not shared_paths:
                return {'success': False, 'error': 'è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨å¤±è´¥'}
            
            # è·å–ä¸»æ–‡ä»¶å¤¹åç§°
            if len(shared_paths) == 1 and shared_paths[0].is_dir:
                # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œä½¿ç”¨è¯¥æ–‡ä»¶å¤¹åç§°
                folder_name = os.path.basename(shared_paths[0].path)
                logger.success(f"è·å–åˆ°æ–‡ä»¶å¤¹åç§°: {folder_name}")
                return {'success': True, 'folder_name': folder_name}
            else:
                # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶æˆ–ä¸æ˜¯æ–‡ä»¶å¤¹ï¼Œä½¿ç”¨åˆ†äº«é“¾æ¥çš„é»˜è®¤åç§°æˆ–ç¬¬ä¸€ä¸ªé¡¹ç›®çš„åç§°
                if shared_paths:
                    first_item = shared_paths[0]
                    if first_item.is_dir:
                        folder_name = os.path.basename(first_item.path)
                    else:
                        # å¦‚æœç¬¬ä¸€ä¸ªæ˜¯æ–‡ä»¶ï¼Œå°è¯•è·å–æ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
                        folder_name = os.path.splitext(os.path.basename(first_item.path))[0]
                    logger.success(f"è·å–åˆ°åç§°: {folder_name}")
                    return {'success': True, 'folder_name': folder_name}
                else:
                    return {'success': False, 'error': 'åˆ†äº«å†…å®¹ä¸ºç©º'}
                    
        except Exception as e:
            logger.error(f"è·å–åˆ†äº«ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}

    def _wait_for_rate_limit(self):
        """ç­‰å¾…è¯·æ±‚é™åˆ¶"""
        current_time = time.time()
        if current_time - self.last_request_time < self.min_request_time:
            wait_time = self.min_request_time - (current_time - self.last_request_time)
            time.sleep(wait_time)
        self.last_request_time = time.time()

    @api_retry(max_retries=1, delay_range=(2, 3))
    def _transfer_shared_paths_with_retry(self, remotedir, fs_ids, uk, share_id, bdstoken, shared_url, client=None):
        """å¸¦é‡è¯•åŠŸèƒ½çš„è½¬å­˜æ–¹æ³•"""
        if client is None:
            client = self.client
        return client.transfer_shared_paths(
            remotedir=remotedir,
            fs_ids=fs_ids,
            uk=uk,
            share_id=share_id,
            bdstoken=bdstoken,
            shared_url=shared_url
        )

    @api_retry(max_retries=1, delay_range=(2, 3))
    def _access_shared_with_retry(self, share_url, pwd=None, client=None):
        """å¸¦é‡è¯•åŠŸèƒ½çš„è®¿é—®åˆ†äº«é“¾æ¥æ–¹æ³•"""
        if client is None:
            client = self.client
        return client.access_shared(share_url, pwd)

    @api_retry(max_retries=1, delay_range=(2, 3))
    def _shared_paths_with_retry(self, shared_url, client=None):
        """å¸¦é‡è¯•åŠŸèƒ½çš„è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨æ–¹æ³•"""
        if client is None:
            client = self.client
        return client.shared_paths(shared_url=shared_url)

    @api_retry(max_retries=1, delay_range=(2, 3))
    def _list_shared_paths_with_retry(self, path, uk, share_id, bdstoken, page=1, size=100, client=None):
        """å¸¦é‡è¯•åŠŸèƒ½çš„è·å–åˆ†äº«ç›®å½•å†…å®¹æ–¹æ³•"""
        if client is None:
            client = self.client
        return client.list_shared_paths(path, uk, share_id, bdstoken, page=page, size=size)

    def list_shared_files(self, share_url, pwd=None):
        """è·å–åˆ†äº«é“¾æ¥ä¸­çš„æ–‡ä»¶åˆ—è¡¨"""
        try:
            logger.info(f"å¼€å§‹è·å–åˆ†äº«é“¾æ¥ {share_url} çš„æ–‡ä»¶åˆ—è¡¨")
            if pwd:
                logger.info(f"ä½¿ç”¨å¯†ç  {pwd} è®¿é—®åˆ†äº«é“¾æ¥")
                
            logger.debug("å¼€å§‹è®¿é—®åˆ†äº«é“¾æ¥...")
            self._access_shared_with_retry(share_url, pwd)
            logger.debug("åˆ†äº«é“¾æ¥è®¿é—®æˆåŠŸ")

            logger.debug("å¼€å§‹è·å–æ–‡ä»¶åˆ—è¡¨...")
            # è·å–æ ¹ç›®å½•æ–‡ä»¶åˆ—è¡¨
            files = self._shared_paths_with_retry(shared_url=share_url)
            
            # ç”¨äºå­˜å‚¨æ‰€æœ‰æ–‡ä»¶
            all_files = []
            
            def get_folder_contents():
                """é€’å½’è·å–æ–‡ä»¶å¤¹å†…å®¹"""
                for file in files:
                    if hasattr(file, 'is_dir') and file.is_dir:
                        logger.debug(f"è¿›å…¥æ–‡ä»¶å¤¹: {file.path}")
                        try:
                            # é€’å½’è·å–å­ç›®å½•å†…å®¹
                            sub_files = self._list_shared_paths_with_retry(
                                file.path,
                                file.uk,
                                file.share_id,
                                file.bdstoken,
                                page=1,
                                size=100
                            )
                            all_files.extend(sub_files)
                        except Exception as e:
                            logger.error(f"è·å–æ–‡ä»¶å¤¹ {file.path} å†…å®¹å¤±è´¥: {str(e)}")
                    else:
                        all_files.append(file)
                        
            # æ‰§è¡Œé€’å½’è·å–
            get_folder_contents()
            logger.info(f"å…±æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")
            return all_files

        except Exception as e:
            logger.error(f"è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
            logger.error(f"å¼‚å¸¸ç±»å‹: {type(e)}")
            logger.error("å¼‚å¸¸è¯¦æƒ…:", exc_info=True)
            raise

    def update_task_status(self, task_url, status, message=None, error=None, transferred_files=None):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€
        Args:
            task_url: ä»»åŠ¡URL
            status: ä»»åŠ¡çŠ¶æ€ (normal/error)
            message: çŠ¶æ€æ¶ˆæ¯
            error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            transferred_files: æˆåŠŸè½¬å­˜çš„æ–‡ä»¶åˆ—è¡¨
        """
        try:
            tasks = self.config['baidu']['tasks']
            for task in tasks:
                if task['url'] == task_url:
                    # çŠ¶æ€è½¬æ¢é€»è¾‘
                    if message and ('æˆåŠŸ' in message or 'æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦è½¬å­˜' in message):
                        task['status'] = 'normal'
                    elif status in ['success', 'skipped', 'pending', 'running']:
                        task['status'] = 'normal'
                    else:
                        task['status'] = 'error'
                        
                    if message:
                        task['message'] = message
                    if error:
                        task['error'] = error
                        task['status'] = 'error'  # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯ï¼Œå¼ºåˆ¶è®¾ç½®ä¸ºé”™è¯¯çŠ¶æ€
                    elif status == 'error' and message:
                        task['error'] = message
                    if transferred_files:
                        task['transferred_files'] = transferred_files
                    
                    # æ·»åŠ æœ€åæ‰§è¡Œæ—¶é—´
                    task['last_execute_time'] = int(time.time())
                    
                    self._save_config()
                    logger.info(f"å·²æ›´æ–°ä»»åŠ¡çŠ¶æ€: {task_url} -> {task['status']} ({message})")
                    return True
            return False
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
            return False

    def is_valid(self):
        """æ£€æŸ¥å­˜å‚¨æ˜¯å¦å¯ç”¨"""
        try:
            # æ£€æŸ¥é…ç½®æ˜¯å¦å­˜åœ¨
            if not self.config or 'baidu' not in self.config:
                return False
                
            # æ£€æŸ¥æ˜¯å¦æœ‰å½“å‰ç”¨æˆ·
            current_user = self.config['baidu'].get('current_user')
            if not current_user:
                return False
                
            # æ£€æŸ¥ç”¨æˆ·ä¿¡æ¯
            try:
                user_info = self.get_user_info()
                return bool(user_info)
            except:
                return False
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥å­˜å‚¨çŠ¶æ€å¤±è´¥: {str(e)}")
            return False
            
    def list_local_files(self, dir_path, client=None):
        """è·å–æœ¬åœ°ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨
        Args:
            dir_path: ç›®å½•è·¯å¾„
            client: å®¢æˆ·ç«¯å®ä¾‹ï¼Œé»˜è®¤ä¸ºNoneåˆ™ä½¿ç”¨self.client
        """
        try:
            if client is None:
                client = self.client

            logger.debug(f"å¼€å§‹è·å–æœ¬åœ°ç›®å½• {dir_path} çš„æ–‡ä»¶åˆ—è¡¨")
            files = []

            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            try:
                # å°è¯•åˆ—å‡ºç›®å½•å†…å®¹æ¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨
                client.list(dir_path)
            except Exception as e:
                if "No such file or directory" in str(e) or "-9" in str(e):
                    logger.info(f"æœ¬åœ°ç›®å½• {dir_path} ä¸å­˜åœ¨ï¼Œå°†åœ¨è½¬å­˜æ—¶åˆ›å»º")
                    return []
                else:
                    logger.error(f"æ£€æŸ¥ç›®å½• {dir_path} æ—¶å‡ºé”™: {str(e)}")

            def _list_dir(path):
                try:
                    content = client.list(path)

                    for item in content:
                        if item.is_file:
                            # åªä¿ç•™æ–‡ä»¶åè¿›è¡Œå¯¹æ¯”
                            file_name = os.path.basename(item.path)
                            files.append(file_name)
                            logger.debug(f"è®°å½•æœ¬åœ°æ–‡ä»¶: {file_name}")
                        elif item.is_dir:
                            _list_dir(item.path)

                except Exception as e:
                    logger.error(f"åˆ—å‡ºç›®å½• {path} å¤±è´¥: {str(e)}")
                    raise

            _list_dir(dir_path)

            # æœ‰åºå±•ç¤ºæ–‡ä»¶åˆ—è¡¨
            if files:
                display_files = files[:20] if len(files) > 20 else files
                logger.info(f"æœ¬åœ°ç›®å½• {dir_path} æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶: {display_files}")
                if len(files) > 20:
                    logger.debug(f"... è¿˜æœ‰ {len(files) - 20} ä¸ªæ–‡ä»¶æœªåœ¨æ—¥å¿—ä¸­æ˜¾ç¤º ...")
            else:
                logger.info(f"æœ¬åœ°ç›®å½• {dir_path} æ‰«æå®Œæˆï¼Œæœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")

            return files

        except Exception as e:
            logger.error(f"è·å–æœ¬åœ°æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
            
    def _extract_file_info(self, file_dict):
        """ä»æ–‡ä»¶å­—å…¸ä¸­æå–æ–‡ä»¶ä¿¡æ¯
        Args:
            file_dict: æ–‡ä»¶ä¿¡æ¯å­—å…¸
        Returns:
            dict: æ ‡å‡†åŒ–çš„æ–‡ä»¶ä¿¡æ¯
        """
        try:
            if isinstance(file_dict, dict):
                # å¦‚æœæ²¡æœ‰ server_filenameï¼Œä»è·¯å¾„ä¸­æå–
                server_filename = file_dict.get('server_filename', '')
                if not server_filename and file_dict.get('path'):
                    server_filename = file_dict['path'].split('/')[-1]
                    
                return {
                    'server_filename': server_filename,
                    'fs_id': file_dict.get('fs_id', ''),
                    'path': file_dict.get('path', ''),
                    'size': file_dict.get('size', 0),
                    'isdir': file_dict.get('isdir', 0)
                }
            return None
        except Exception as e:
            logger.error(f"æå–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None

    def _list_shared_dir_files(self, path, uk, share_id, bdstoken, client=None):
        """é€’å½’è·å–å…±äº«ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        Args:
            path: ç›®å½•è·¯å¾„
            uk: ç”¨æˆ·uk
            share_id: åˆ†äº«ID
            bdstoken: token
            client: å®¢æˆ·ç«¯å®ä¾‹ï¼Œé»˜è®¤ä¸ºNoneåˆ™ä½¿ç”¨self.client
        Returns:
            list: æ–‡ä»¶åˆ—è¡¨
        """
        if client is None:
            client = self.client

        files = []
        try:
            # åˆ†é¡µè·å–æ‰€æœ‰æ–‡ä»¶
            page = 1
            page_size = 100
            all_sub_files = []

            while True:
                sub_paths = self._list_shared_paths_with_retry(
                    path.path,
                    uk,
                    share_id,
                    bdstoken,
                    page=page,
                    size=page_size,
                    client=client
                )
                
                if isinstance(sub_paths, list):
                    sub_files = sub_paths
                elif isinstance(sub_paths, dict):
                    sub_files = sub_paths.get('list', [])
                else:
                    logger.error(f"å­ç›®å½•å†…å®¹æ ¼å¼é”™è¯¯: {type(sub_paths)}")
                    break
                
                if not sub_files:
                    # æ²¡æœ‰æ›´å¤šæ–‡ä»¶äº†
                    break
                
                all_sub_files.extend(sub_files)
                
                # å¦‚æœå½“å‰é¡µæ–‡ä»¶æ•°å°‘äºé¡µå¤§å°ï¼Œè¯´æ˜å·²ç»æ˜¯æœ€åä¸€é¡µ
                if len(sub_files) < page_size:
                    break
                
                page += 1
            
            logger.info(f"ç›®å½• {path.path} å…±è·å–åˆ° {len(all_sub_files)} ä¸ªæ–‡ä»¶/å­ç›®å½•")
            
            sub_files = all_sub_files
                
            for sub_file in sub_files:
                if hasattr(sub_file, '_asdict'):
                    sub_file_dict = sub_file._asdict()
                else:
                    sub_file_dict = sub_file if isinstance(sub_file, dict) else {}
                    
                # å¦‚æœæ˜¯ç›®å½•ï¼Œé€’å½’è·å–
                if sub_file.is_dir:
                    logger.info(f"é€’å½’å¤„ç†å­ç›®å½•: {sub_file.path}")
                    sub_dir_files = self._list_shared_dir_files(sub_file, uk, share_id, bdstoken, client=client)
                    files.extend(sub_dir_files)
                else:
                    # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œæ·»åŠ åˆ°åˆ—è¡¨
                    file_info = self._extract_file_info(sub_file_dict)
                    if file_info:
                        # å»æ‰è·¯å¾„ä¸­çš„ sharelink éƒ¨åˆ†
                        file_info['path'] = re.sub(r'^/sharelink\d*-\d+/?', '', sub_file.path)
                        # å»æ‰å¼€å¤´çš„æ–œæ 
                        file_info['path'] = file_info['path'].lstrip('/')
                        files.append(file_info)
                        logger.debug(f"è®°å½•å…±äº«æ–‡ä»¶: {file_info}")
                
        except Exception as e:
            logger.error(f"è·å–ç›®å½• {path.path} å†…å®¹å¤±è´¥: {str(e)}")
            
        return files

    def update_user(self, username, cookies):
        """æ›´æ–°ç”¨æˆ·ä¿¡æ¯
        Args:
            username: ç”¨æˆ·å
            cookies: æ–°çš„cookieså­—ç¬¦ä¸²
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if not username:
                raise ValueError("ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
            
            if username not in self.config['baidu']['users']:
                raise ValueError(f"ç”¨æˆ· {username} ä¸å­˜åœ¨")
            
            # éªŒè¯æ–°cookiesæ˜¯å¦æœ‰æ•ˆ
            cookies_dict = self._parse_cookies(cookies)
            if not self._validate_cookies(cookies_dict):
                raise ValueError("æ— æ•ˆçš„cookiesæ ¼å¼")
            
            # éªŒè¯cookiesæ˜¯å¦å¯ç”¨
            try:
                temp_api = BaiduPCSApi(cookies=cookies_dict)
                user_info = temp_api.user_info()
                if not user_info:
                    raise ValueError("Cookiesæ— æ•ˆ")
            except Exception as e:
                raise ValueError(f"éªŒè¯cookieså¤±è´¥: {str(e)}")
            
            # æ›´æ–°ç”¨æˆ·ä¿¡æ¯
            self.config['baidu']['users'][username].update({
                'cookies': cookies,
                'name': username,
                'user_id': username
            })
            
            self._save_config()
            
            # å¦‚æœæ›´æ–°çš„æ˜¯å½“å‰ç”¨æˆ·,é‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
            if username == self.config['baidu']['current_user']:
                self._init_client()
                # æ¸…é™¤ç”¨æˆ·ä¿¡æ¯ç¼“å­˜
                self._clear_user_info_cache()
            
            logger.success(f"æ›´æ–°ç”¨æˆ·æˆåŠŸ: {username}")
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°ç”¨æˆ·å¤±è´¥: {str(e)}")
            return False

    def get_user(self, username):
        """è·å–ç”¨æˆ·ä¿¡æ¯
        Args:
            username: ç”¨æˆ·å
        Returns:
            dict: ç”¨æˆ·ä¿¡æ¯,ä¸å­˜åœ¨è¿”å›None
        """
        try:
            if not username:
                return None
            
            if username not in self.config['baidu']['users']:
                return None
            
            user_info = self.config['baidu']['users'][username]
            return {
                'username': username,
                'name': user_info.get('name', username),
                'user_id': user_info.get('user_id', username),
                'cookies': user_info.get('cookies', '')
            }
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None

    def update_task(self, index, task_data):
        """æ›´æ–°ä»»åŠ¡ä¿¡æ¯"""
        try:
            tasks = self.config['baidu']['tasks']
            if not (0 <= index < len(tasks)):
                raise ValueError("ä»»åŠ¡ç´¢å¼•æ— æ•ˆ")
            
            # ä¿å­˜æ—§ä»»åŠ¡é…ç½®ç”¨äºæ¯”è¾ƒ
            old_task = tasks[index].copy()
            
            # éªŒè¯å’Œæ¸…ç†æ•°æ®
            url = task_data.get('url', '').strip()
            if not url:
                raise ValueError("åˆ†äº«é“¾æ¥ä¸èƒ½ä¸ºç©º")
            
            # ç§»é™¤hashéƒ¨åˆ†
            url = url.split('#')[0]
            
            # éªŒè¯URLæ ¼å¼
            if not re.match(r'^https?://pan\.baidu\.com/s/[a-zA-Z0-9_-]+(\?pwd=[a-zA-Z0-9]+)?$', url):
                raise ValueError("æ— æ•ˆçš„ç™¾åº¦ç½‘ç›˜åˆ†äº«é“¾æ¥æ ¼å¼")
            
            # æ›´æ–°ä»»åŠ¡ä¿¡æ¯
            tasks[index].update({
                'name': task_data.get('name', '').strip() or old_task.get('name', ''),
                'url': url,
                'save_dir': task_data.get('save_dir', '').strip() or old_task.get('save_dir', ''),
                'pwd': task_data.get('pwd') if task_data.get('pwd') is not None else old_task.get('pwd'),
                'status': 'pending',  # é‡ç½®ä»»åŠ¡çŠ¶æ€
                'last_update': int(time.time())  # æ·»åŠ æ›´æ–°æ—¶é—´æˆ³
            })
            
            # å¤„ç†åˆ†ç±»å­—æ®µ
            if 'category' in task_data:
                category = task_data['category'].strip()
                if category:  # å¦‚æœæœ‰æ–°åˆ†ç±»
                    tasks[index]['category'] = category
                else:  # å¦‚æœåˆ†ç±»ä¸ºç©ºï¼Œåˆ é™¤åˆ†ç±»å­—æ®µ
                    tasks[index].pop('category', None)
            
            # å¤„ç†cronå­—æ®µ
            new_cron = task_data.get('cron')
            if new_cron is not None:
                if isinstance(new_cron, str) and new_cron.strip():
                    tasks[index]['cron'] = new_cron.strip()
                else:
                    # å¦‚æœæ–°cronä¸ºç©ºæˆ–æ— æ•ˆ,åˆ é™¤cronå­—æ®µ
                    tasks[index].pop('cron', None)
            
            # ä¿å­˜é…ç½®å¹¶æ›´æ–°è°ƒåº¦å™¨
            self._save_config()
            
            # æ›´æ–°è°ƒåº¦å™¨
            from scheduler import TaskScheduler
            if hasattr(TaskScheduler, 'instance') and TaskScheduler.instance:
                TaskScheduler.instance.update_task_schedule(url, tasks[index].get('cron'))
                logger.info(f"å·²æ›´æ–°ä»»åŠ¡è°ƒåº¦: {url}")
            
            logger.success(f"æ›´æ–°ä»»åŠ¡æˆåŠŸ: {tasks[index]}")
            return True, True  # ç¬¬äºŒä¸ªTrueè¡¨ç¤ºè°ƒåº¦å™¨å·²æ›´æ–°
            
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False, False

    def get_task_categories(self):
        """è·å–æ‰€æœ‰ä»»åŠ¡åˆ†ç±»
        Returns:
            list: åˆ†ç±»åˆ—è¡¨
        """
        try:
            tasks = self.config['baidu'].get('tasks', [])
            # æ”¶é›†æ‰€æœ‰éç©ºçš„åˆ†ç±»
            categories = {task.get('category') for task in tasks if task.get('category') and task.get('category').strip()}
            # è¿”å›æ’åºåçš„åˆ†ç±»åˆ—è¡¨ï¼Œè¿‡æ»¤æ‰ç©ºå€¼
            return sorted([cat for cat in categories if cat])
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡åˆ†ç±»å¤±è´¥: {str(e)}")
            return []

    def get_tasks_by_category(self, category=None):
        """è·å–æŒ‡å®šåˆ†ç±»çš„ä»»åŠ¡
        Args:
            category: åˆ†ç±»åç§°ï¼ŒNoneè¡¨ç¤ºè·å–æœªåˆ†ç±»ä»»åŠ¡
        Returns:
            list: ä»»åŠ¡åˆ—è¡¨
        """
        try:
            tasks = self.config['baidu'].get('tasks', [])
            if category is None:
                # è¿”å›æœªåˆ†ç±»çš„ä»»åŠ¡
                return [task for task in tasks if 'category' not in task]
            else:
                # è¿”å›æŒ‡å®šåˆ†ç±»çš„ä»»åŠ¡
                return [task for task in tasks if task.get('category') == category]
        except Exception as e:
            logger.error(f"è·å–åˆ†ç±»ä»»åŠ¡å¤±è´¥: {str(e)}")
            return []

    def remove_tasks(self, orders):
        """æ‰¹é‡åˆ é™¤è½¬å­˜ä»»åŠ¡
        Args:
            orders: è¦åˆ é™¤çš„ä»»åŠ¡é¡ºåºåˆ—è¡¨
        Returns:
            int: æˆåŠŸåˆ é™¤çš„ä»»åŠ¡æ•°é‡
        """
        try:
            if not orders:
                return 0
            
            tasks = self.config['baidu']['tasks']
            original_count = len(tasks)
            
            # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼è¿‡æ»¤æ‰è¦åˆ é™¤çš„ä»»åŠ¡
            self.config['baidu']['tasks'] = [
                task for task in tasks 
                if task.get('order') not in orders
            ]
            
            # è®¡ç®—å®é™…åˆ é™¤çš„ä»»åŠ¡æ•°
            deleted_count = original_count - len(self.config['baidu']['tasks'])
            
            if deleted_count > 0:
                # ä¿å­˜é…ç½®å¹¶æ›´æ–°è°ƒåº¦å™¨
                self._save_config(update_scheduler=True)
                # é‡æ–°æ•´ç†å‰©ä½™ä»»åŠ¡çš„é¡ºåº
                self._update_task_orders()
                logger.success(f"æ‰¹é‡åˆ é™¤ä»»åŠ¡æˆåŠŸ: åˆ é™¤äº†{deleted_count}ä¸ªä»»åŠ¡")
            
            return deleted_count
            
        except Exception as e:
            logger.error(f"æ‰¹é‡åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}")
            raise

    def update_task_status_by_order(self, order, status, message=None, error=None, transferred_files=None):
        """åŸºäºorderæ›´æ–°ä»»åŠ¡çŠ¶æ€
        Args:
            order: ä»»åŠ¡é¡ºåºå·
            status: ä»»åŠ¡çŠ¶æ€ (normal/error)
            message: çŠ¶æ€æ¶ˆæ¯
            error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            transferred_files: æˆåŠŸè½¬å­˜çš„æ–‡ä»¶åˆ—è¡¨
        """
        try:
            tasks = self.config['baidu']['tasks']
            for task in tasks:
                if task.get('order') == order:
                    # çŠ¶æ€è½¬æ¢é€»è¾‘
                    if message and ('æˆåŠŸ' in message or 'æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦è½¬å­˜' in message):
                        task['status'] = 'normal'
                    elif status in ['success', 'skipped', 'pending', 'running']:
                        task['status'] = 'normal'
                    else:
                        task['status'] = 'error'
                        
                    if message:
                        task['message'] = message
                    if error:
                        task['error'] = error
                        task['status'] = 'error'  # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯ï¼Œå¼ºåˆ¶è®¾ç½®ä¸ºé”™è¯¯çŠ¶æ€
                    elif status == 'error' and message:
                        task['error'] = message
                    if transferred_files:
                        task['transferred_files'] = transferred_files
                    
                    # æ·»åŠ æœ€åæ‰§è¡Œæ—¶é—´
                    task['last_execute_time'] = int(time.time())
                    
                    self._save_config()
                    logger.info(f"å·²æ›´æ–°ä»»åŠ¡çŠ¶æ€: order={order} -> {task['status']} ({message})")
                    return True
            return False
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
            return False

    def remove_task_by_order(self, order):
        """åŸºäºorderåˆ é™¤è½¬å­˜ä»»åŠ¡
        Args:
            order: ä»»åŠ¡é¡ºåºå·
        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            tasks = self.config['baidu']['tasks']
            for i, task in enumerate(tasks):
                if task.get('order') == order:
                    tasks.pop(i)
                    # ç¡®ä¿æ›´æ–°è°ƒåº¦å™¨
                    self._save_config(update_scheduler=True)
                    # é‡æ–°æ•´ç†å‰©ä½™ä»»åŠ¡çš„é¡ºåº
                    self._update_task_orders()
                    logger.success(f"åˆ é™¤ä»»åŠ¡æˆåŠŸ: order={order}")
                    return True
            logger.warning(f"æœªæ‰¾åˆ°ä»»åŠ¡: order={order}")
            return False
        except Exception as e:
            logger.error(f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False

    def update_task_by_order(self, order, task_data):
        """åŸºäºorderæ›´æ–°ä»»åŠ¡ä¿¡æ¯
        Args:
            order: ä»»åŠ¡é¡ºåºå·
            task_data: æ–°çš„ä»»åŠ¡æ•°æ®
        Returns:
            bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            tasks = self.config['baidu']['tasks']
            task_index = None
            for i, task in enumerate(tasks):
                if task.get('order') == order:
                    task_index = i
                    break
                    
            if task_index is None:
                raise ValueError(f"æœªæ‰¾åˆ°ä»»åŠ¡: order={order}")
            
            # ä¿å­˜æ—§ä»»åŠ¡é…ç½®ç”¨äºæ¯”è¾ƒ
            old_task = tasks[task_index].copy()
            
            # éªŒè¯å’Œæ¸…ç†æ•°æ®
            url = task_data.get('url', '').strip()
            if not url:
                raise ValueError("åˆ†äº«é“¾æ¥ä¸èƒ½ä¸ºç©º")
            
            # ç§»é™¤hashéƒ¨åˆ†
            url = url.split('#')[0]
            
            # éªŒè¯URLæ ¼å¼
            if not re.match(r'^https?://pan\.baidu\.com/s/[a-zA-Z0-9_-]+(\?pwd=[a-zA-Z0-9]+)?$', url):
                raise ValueError("æ— æ•ˆçš„ç™¾åº¦ç½‘ç›˜åˆ†äº«é“¾æ¥æ ¼å¼")
            
            # æ›´æ–°ä»»åŠ¡ä¿¡æ¯
            tasks[task_index].update({
                'name': task_data.get('name', '').strip() or old_task.get('name', ''),
                'url': url,
                'save_dir': task_data.get('save_dir', '').strip() or old_task.get('save_dir', ''),
                'pwd': task_data.get('pwd') if task_data.get('pwd') is not None else old_task.get('pwd'),
                'status': task_data.get('status', old_task.get('status', 'normal')),  # ä¿æŒåŸæœ‰çŠ¶æ€
                'message': task_data.get('message', old_task.get('message', '')),  # ä¿æŒåŸæœ‰æ¶ˆæ¯
                'last_update': int(time.time())  # æ·»åŠ æ›´æ–°æ—¶é—´æˆ³
            })
            
            # å¤„ç†åˆ†ç±»å­—æ®µ
            if 'category' in task_data:
                category = task_data['category'].strip()
                if category:  # å¦‚æœæœ‰æ–°åˆ†ç±»
                    tasks[task_index]['category'] = category
                else:  # å¦‚æœåˆ†ç±»ä¸ºç©ºï¼Œåˆ é™¤åˆ†ç±»å­—æ®µ
                    tasks[task_index].pop('category', None)
            
            # å¤„ç†cronå­—æ®µ
            new_cron = task_data.get('cron')
            if new_cron is not None:
                if isinstance(new_cron, str) and new_cron.strip():
                    tasks[task_index]['cron'] = new_cron.strip()
                else:
                    # å¦‚æœæ–°cronä¸ºç©ºæˆ–æ— æ•ˆ,åˆ é™¤cronå­—æ®µ
                    tasks[task_index].pop('cron', None)
            
            # å¤„ç†æ­£åˆ™è¡¨è¾¾å¼å­—æ®µ
            if 'regex_pattern' in task_data:
                regex_pattern = task_data['regex_pattern']
                if regex_pattern and regex_pattern.strip():
                    tasks[task_index]['regex_pattern'] = regex_pattern.strip()
                    # å¤„ç†æ›¿æ¢è¡¨è¾¾å¼ï¼Œå¯ä»¥ä¸ºç©º
                    regex_replace = task_data.get('regex_replace', '')
                    tasks[task_index]['regex_replace'] = regex_replace.strip() if regex_replace else ''
                else:
                    # å¦‚æœè¿‡æ»¤è¡¨è¾¾å¼ä¸ºç©ºï¼Œåˆ é™¤ç›¸å…³å­—æ®µ
                    tasks[task_index].pop('regex_pattern', None)
                    tasks[task_index].pop('regex_replace', None)
            
            # ä¿å­˜é…ç½®å¹¶æ›´æ–°è°ƒåº¦å™¨
            self._save_config()
            
            # æ›´æ–°è°ƒåº¦å™¨
            from scheduler import TaskScheduler
            if hasattr(TaskScheduler, 'instance') and TaskScheduler.instance:
                TaskScheduler.instance.update_task_schedule(url, tasks[task_index].get('cron'))
                logger.info(f"å·²æ›´æ–°ä»»åŠ¡è°ƒåº¦: {url}")
            
            logger.success(f"æ›´æ–°ä»»åŠ¡æˆåŠŸ: {tasks[task_index]}")
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False

    def ensure_dir_exists(self, remote_dir):
        """ç¡®ä¿è¿œç¨‹ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
        try:
            if not remote_dir.startswith('/'):
                remote_dir = '/' + remote_dir
                
            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            cmd = f'BaiduPCS-Py ls "{remote_dir}"'
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
            if result.returncode != 0 and "No such file or directory" in result.stderr:
                cmd = f'BaiduPCS-Py mkdir "{remote_dir}"'
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                
                if result.returncode != 0:
                    raise Exception(f"åˆ›å»ºç›®å½•å¤±è´¥: {result.stderr}")
                    
            return True
        except Exception as e:
            logger.error(f"ç¡®ä¿ç›®å½•å­˜åœ¨å¤±è´¥: {str(e)}")
            raise

    def share_file(self, remote_path, password=None, period_days=None):
        """åˆ†äº«è¿œç¨‹æ–‡ä»¶æˆ–ç›®å½•
        
        Args:
            remote_path: è¦åˆ†äº«çš„è¿œç¨‹è·¯å¾„
            password: åˆ†äº«å¯†ç ï¼Œ4ä¸ªå­—ç¬¦ï¼Œå¯é€‰
            period_days: æœ‰æ•ˆæœŸï¼Œå•ä½ä¸ºå¤©ï¼Œå¯é€‰
            
        Returns:
            dict: åŒ…å«åˆ†äº«ç»“æœçš„å­—å…¸
        """
        try:
            if not remote_path.startswith('/'):
                remote_path = '/' + remote_path
                
            # éªŒè¯å¯†ç é•¿åº¦
            if password and len(password) != 4:
                return {'success': False, 'error': 'å¯†ç å¿…é¡»æ˜¯4ä¸ªå­—ç¬¦'}
            
            # å…ˆæ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            try:
                logger.info(f"æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨: {remote_path}")
                self.client.list(remote_path)
                logger.info(f"ç›®å½•å·²å­˜åœ¨: {remote_path}")
            except Exception as e:
                logger.info(f"ç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º: {remote_path}")
                if not self._ensure_dir_tree_exists(remote_path):
                    error_msg = f"æ— æ³•åˆ›å»ºç›®å½•: {remote_path}"
                    logger.error(error_msg)
                    return {'success': False, 'error': error_msg}
                logger.success(f"æˆåŠŸåˆ›å»ºç›®å½•: {remote_path}")
            
            # è°ƒç”¨APIåˆ†äº«æ–‡ä»¶
            # BaiduPCSApi.shareæ–¹æ³•è¦æ±‚passwordå‚æ•°ï¼Œå¦‚æœä¸ºNoneåˆ™ä¼ ç©ºå­—ç¬¦ä¸²
            # periodå‚æ•°ä¸º0è¡¨ç¤ºæ°¸ä¹…æœ‰æ•ˆ
            logger.info(f"å¼€å§‹åˆ†äº«æ–‡ä»¶: {remote_path}")
            link = self.client.share(
                remote_path, 
                password=password or "", 
                period=period_days or 0
            )
            
            # æ„å»ºè¿”å›ç»“æœ
            share_info = {
                'url': link.url,
                'password': link.password,
                'create_time': int(time.time()),
                'period_days': period_days,
                'remote_path': remote_path
            }
            
            logger.success(f"åˆ†äº«æ–‡ä»¶æˆåŠŸ: {remote_path} -> {link.url}")
            return {
                'success': True,
                'share_info': share_info
            }
                
        except Exception as e:
            logger.error(f"åˆ†äº«æ–‡ä»¶å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}

    def update_task_share_info(self, task_order, share_info):
        """æ›´æ–°ä»»åŠ¡çš„åˆ†äº«ä¿¡æ¯
        
        Args:
            task_order: ä»»åŠ¡çš„order
            share_info: åˆ†äº«ä¿¡æ¯å­—å…¸
        """
        try:
            tasks = self.list_tasks()
            for task in tasks:
                if task.get('order') == task_order:
                    task['share_info'] = share_info
                    self._save_config()
                    return True
            return False
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡åˆ†äº«ä¿¡æ¯å¤±è´¥: {str(e)}")
            return False
